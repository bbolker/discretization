
@misc{fox_why_2016,
	title = {Why don’t more ecologists use strong inference?},
	url = {https://dynamicecology.wordpress.com/2016/06/01/obstacles-to-strong-inference-in-ecology/},
	abstract = {Platt (1964 Science) is a classic practical statement of philosophy of science by a scientist. Briefly, Platt argues that some fields of science progress faster than others, and that this is neithe…},
	urldate = {2016-07-02},
	journal = {Dynamic Ecology},
	author = {Fox, Jeremy},
	year = {2016},
	file = {Snapshot:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/KNSK83UK/comment-page-1.html:text/html}
}

@misc{mcgill_why_2016,
	title = {Why ecology is hard (and fun) – multicausality},
	url = {https://dynamicecology.wordpress.com/2016/03/02/why-ecology-is-hard-and-fun-multicausality/},
	abstract = {Mark recently wrote a piece musing on the true fact that many ecologists have evolution envy   – wishing to find simply general rules in ecology that match the elegance of evolution, which wa…},
	urldate = {2016-07-02},
	journal = {Dynamic Ecology},
	author = {McGill, Brian},
	year = {2016},
	file = {Snapshot:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/CDSVG8MC/why-ecology-is-hard-and-fun-multicausality.html:text/html}
}


@article{platt_strong_1964,
	series = {New {Series}},
	title = {Strong {Inference}},
	volume = {146},
	issn = {00368075},
	url = {http://www.jstor.org/stable/1714268},
	doi = {10.2307/1714268},
	number = {3642},
	urldate = {2009-04-14},
	journal = {Science},
	author = {Platt, John R.},
	year = {1964},
	note = {ArticleType: primary\_article / Full publication date: Oct. 16, 1964 / Copyright © 1964 American Association for the Advancement of Science},
	pages = {347--353}
}


@article{barker_truth_2015,
	title = {Truth, models, model sets, {AIC}, and multimodel inference: {A} {Bayesian} perspective},
	volume = {79},
	copyright = {Published 2015. This article is a U.S. Government work and is in the public domain in the USA.},
	issn = {1937-2817},
	shorttitle = {Truth, models, model sets, {AIC}, and multimodel inference},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/jwmg.890/abstract},
	doi = {10.1002/jwmg.890},
	abstract = {Statistical inference begins with viewing data as realizations of stochastic processes. Mathematical models provide partial descriptions of these processes; inference is the process of using the data to obtain a more complete description of the stochastic processes. Wildlife and ecological scientists have become increasingly concerned with the conditional nature of model-based inference: what if the model is wrong? Over the last 2 decades, Akaike's Information Criterion (AIC) has been widely and increasingly used in wildlife statistics for 2 related purposes, first for model choice and second to quantify model uncertainty. We argue that for the second of these purposes, the Bayesian paradigm provides the natural framework for describing uncertainty associated with model choice and provides the most easily communicated basis for model weighting. Moreover, Bayesian arguments provide the sole justification for interpreting model weights (including AIC weights) as coherent (mathematically self consistent) model probabilities. This interpretation requires treating the model as an exact description of the data-generating mechanism. We discuss the implications of this assumption, and conclude that more emphasis is needed on model checking to provide confidence in the quality of inference. Published 2015. This article is a U.S. Government work and is in the public domain in the USA.},
	language = {en},
	number = {5},
	urldate = {2015-07-10},
	journal = {The Journal of Wildlife Management},
	author = {Barker, Richard J. and Link, William A.},
	year = {2015},
	keywords = {AIC, Bayesian analysis, BIC, DIC, model selection, multi-model inference},
	pages = {730--738}
}


@article{luttbeg_comparing_2004,
	title = {Comparing {Alternative} {Models} to {Empirical} {Data}: {Cognitive} {Models} of {Western} {Scrub}-{Jay} {Foraging} {Behavior}},
	volume = {163},
	issn = {0003-0147},
	shorttitle = {Comparing {Alternative} {Models} to {Empirical} {Data}},
	url = {http://www.jstor.org/stable/10.1086/381319},
	doi = {10.1086/381319},
	abstract = {Abstract: Animals often select one item from a set of candidates, as when choosing a foraging site or mate, and are expected to possess accurate and efficient rules for acquiring information and making decisions. Little is known, however, about the decision rules animals use. We compare patterns of information sampling by western scrub-jays (Aphelocoma californica) when choosing a nut with three decision rules: best of n (BN), flexible threshold (FT), and comparative Bayes (CB). First, we use a null hypothesis testing approach and find that the CB decision rule, in which individuals use past experiences to make nonrandom assessment and choice decisions, produces patterns of behavior that more closely correspond to observed patterns of nut sampling in scrub-jays than the other two rules. This approach does not allow us to quantify how much better CB is at predicting scrub-jay behavior than the other decision rules. Second, we use a model selection approach that uses Akaike Information Criteria to quantify how well alternative models approximate observed data. We find that the CB rule is much more likely to produce the observed patterns of scrub-jay behavior than the other rules. This result provides some of the best empirical evidence of the use of Bayesian information updating by a nonhuman animal.},
	number = {2},
	urldate = {2016-07-02},
	journal = {The American Naturalist},
	author = {Luttbeg, Barney and Langen, Tom A. and Adams, Associate Editor: Eldridge S.},
	year = {2004},
	pages = {263--276}
}


@article{cade_model_2015,
	title = {Model averaging and muddled multimodel inference},
	issn = {0012-9658},
	url = {http://www.esajournals.org/doi/abs/10.1890/14-1639.1},
	doi = {10.1890/14-1639.1},
	abstract = {Three flawed practices associated with model averaging coefficients for predictor variables in regression models commonly occur when making multimodel inferences in analyses of ecological data.  Model-averaged regression coefficients based on Akaike Information Criterion (AIC) weights were recommended by Burnham and Anderson (2002, 2004) for addressing model uncertainty but they are not valid, interpretable estimates of partial effects for individual predictors when there is multicollinearity among the predictor variables.  Multicollinearity implies that the scaling of units in the denominators of the regression coefficients may change across models such that neither the parameters nor their estimates have common scales, and thus averaging them makes no sense.  The associated sums of AIC model weights recommended to assess relative importance of individual predictors are a measure of relative importance of models, with little information about contributions by individual predictors.  Sometimes the model-averaged regression coefficients for predictor variables are incorrectly used to make model-averaged predictions of the response variable when the models are not linear in the parameters.  I demonstrate the issues with the first two practices using the college grade point average example extensively analyzed by Burnham and Anderson (2002).  I show how partial standard deviations of the predictor variables can be used to detect changing scales of their estimates with multicollinearity.  Standardizing estimates based on partial standard deviations for their variables can be used to make the scaling of the estimates commensurate across models, a necessary but not sufficient condition for model averaging of the estimates to be sensible.  The standardized estimates or equivalently the t-statistics on unstandardized estimates also can be used to provide more informative measures of relative importance than sums of AIC weights.  Finally, I illustrate how seriously compromised statistical interpretations and predictions can be for all three of these flawed practices by critiquing their use in a recent species distribution modeling technique developed by Rice et al. (2013) for predicting greater sage-grouse (Centrocercus urophasianus) distribution in Colorado.  These model averaging issues are common in other ecological literature and ought to be discontinued if we are to make effective scientific contributions to ecological knowledge and conservation of natural resources.},
	urldate = {2015-03-22},
	journal = {Ecology},
	author = {Cade, Brian S.},
	year = {2015}
}


@article{grueber_multimodel_2011,
	title = {Multimodel inference in ecology and evolution: challenges and solutions},
	volume = {24},
	issn = {1420-9101},
	shorttitle = {Multimodel inference in ecology and evolution},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1420-9101.2010.02210.x/abstract},
	doi = {10.1111/j.1420-9101.2010.02210.x},
	abstract = {Information theoretic approaches and model averaging are increasing in popularity, but this approach can be difficult to apply to the realistic, complex models that typify many ecological and evolutionary analyses. This is especially true for those researchers without a formal background in information theory. Here, we highlight a number of practical obstacles to model averaging complex models. Although not meant to be an exhaustive review, we identify several important issues with tentative solutions where they exist (e.g. dealing with collinearity amongst predictors; how to compute model-averaged parameters) and highlight areas for future research where solutions are not clear (e.g. when to use random intercepts or slopes; which information criteria to use when random factors are involved). We also provide a worked example of a mixed model analysis of inbreeding depression in a wild population. By providing an overview of these issues, we hope that this approach will become more accessible to those investigating any process where multiple variables impact an evolutionary or ecological response.},
	language = {en},
	number = {4},
	urldate = {2011-12-15},
	journal = {Journal of Evolutionary Biology},
	author = {Grueber, C. E and Nakagawa, S. and Laws, R. J and Jamieson, I. G},
	year = {2011},
	keywords = {Akaike Information Criterion, generalized linear mixed models, inbreeding, information theory, lethal equivalents, model averaging, random factors, standardized predictors},
	pages = {699--711},
	file = {Wiley Full Text PDF:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/UF4UKU6C/Grueber et al. - 2011 - Multimodel inference in ecology and evolution cha.pdf:application/pdf}
}


@article{brewer_relative_2016,
	title = {The relative performance of {AIC}, {AICC} and {BIC} in the presence of unobserved heterogeneity},
	volume = {7},
	issn = {2041-210X},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12541/abstract},
	doi = {10.1111/2041-210X.12541},
	abstract = {* Model selection is difficult. Even in the apparently straightforward case of choosing between standard linear regression models, there does not yet appear to be consensus in the statistical ecology literature as to the right approach.


* We review recent works on model selection in ecology and subsequently focus on one aspect in particular: the use of the Akaike Information Criterion (AIC) or its small-sample equivalent, AICC. We create a novel framework for simulation studies and use this to study model selection from simulated data sets with a range of properties, which differ in terms of degree of unobserved heterogeneity. We use the results of the simulation study to suggest an approach for model selection based on ideas from information criteria but requiring simulation.


* We find that the relative predictive performance of model selection by different information criteria is heavily dependent on the degree of unobserved heterogeneity between data sets. When heterogeneity is small, AIC or AICC are likely to perform well, but if heterogeneity is large, the Bayesian Information Criterion (BIC) will often perform better, due to the stronger penalty afforded.


* Our conclusion is that the choice of information criterion (or more broadly, the strength of likelihood penalty) should ideally be based upon hypothesized (or estimated from previous data) properties of the population of data sets from which a given data set could have arisen. Relying on a single form of information criterion is unlikely to be universally successful.},
	language = {en},
	number = {6},
	urldate = {2016-06-23},
	journal = {Methods in Ecology and Evolution},
	author = {Brewer, Mark J. and Butler, Adam and Cooksley, Susan L.},
	year = {2016},
	keywords = {Akaike Information Criterion, Bayesian information criterion, generalized linear models, likelihood penalization, linear regression, model selection, statistical controversies},
	pages = {679--692},
	file = {Full Text PDF:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/WFFXG22A/Brewer et al. - 2016 - The relative performance of AIC, AICC and BIC in t.pdf:application/pdf;Snapshot:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/PSTBSECK/abstract.html:text/html}
}


@article{dahlgren_alternative_2010,
	title = {Alternative regression methods are not considered in {Murtaugh} (2009) or by ecologists in general},
	volume = {13},
	issn = {1461-0248},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1461-0248.2010.01460.x/abstract},
	doi = {10.1111/j.1461-0248.2010.01460.x},
	abstract = {Ecology Letters (2010) 13: E7–E9 
Abstract
Murtaugh (2009) recently illustrated that all subsets variable selection is very similar to stepwise regression. This, however, does not necessarily mean both methods are useful. On the contrary, the same problems with overfitting should apply. Ecologists should, if model building is indeed necessary, consider more reliable regression methods now available.},
	language = {en},
	number = {5},
	urldate = {2016-04-14},
	journal = {Ecology Letters},
	author = {Dahlgren, Johan P.},
	year = {2010},
	keywords = {AIC, all subsets, BIC, lasso, ridge regression, Shrinkage, stepwise multiple regression, Variable selection},
	pages = {E7--E9},
	file = {Snapshot:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/ZKQHERDI/abstract.html:text/html}
}


@misc{mcgill_why_2015,
	title = {Why {AIC} appeals to ecologist’s lowest instincts},
	url = {https://dynamicecology.wordpress.com/2015/05/21/why-aic-appeals-to-ecologists-lowest-instincts/},
	urldate = {2015-06-27},
	journal = {Dynamic Ecology},
	author = {McGill, Brian J},
	year = {2015}
}


@article{javanmard_confidence_2014,
	title = {Confidence intervals and hypothesis testing for high-dimensional regression},
	volume = {15},
	url = {http://dl.acm.org/citation.cfm?id=2697057},
	number = {1},
	urldate = {2016-05-24},
	journal = {The Journal of Machine Learning Research},
	author = {Javanmard, Adel and Montanari, Andrea},
	year = {2014},
	pages = {2869--2909},
	file = {javanmard14a.pdf:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/2G8DE2IT/javanmard14a.pdf:application/pdf}
}


@article{lockhart_significance_2014,
	title = {A significance test for the lasso},
	volume = {42},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4285373/},
	number = {2},
	urldate = {2016-05-24},
	journal = {Annals of statistics},
	author = {Lockhart, Richard and Taylor, Jonathan and Tibshirani, Ryan J. and Tibshirani, Robert},
	year = {2014},
	pages = {413}
}


@article{lee_exact_2013,
	title = {Exact post-selection inference with the lasso},
	url = {http://xxx.tau.ac.il/abs/1311.6238v4},
	urldate = {2015-07-10},
	author = {Lee, Jason D. and Sun, Dennis L. and Sun, Yuekai and Taylor, Jonathan E.},
	year = {2013}
}


@article{potscherConfidence2010a,
  title = {Confidence Sets Based on Penalized Maximum Likelihood Estimators in {{Gaussian}} Regression},
  author = {P{\"o}tscher, Benedikt M. and Schneider, Ulrike},
  year = {2010},
  month = jan,
  journal = {Electronic Journal of Statistics},
  volume = {4},
  pages = {334--360},
  publisher = {{Institute of Mathematical Statistics and Bernoulli Society}},
  issn = {1935-7524, 1935-7524},
  doi = {10.1214/09-EJS523},
  urldate = {2023-07-23},
  abstract = {Confidence intervals based on penalized maximum likelihood estimators such as the LASSO, adaptive LASSO, and hard-thresholding are analyzed. In the known-variance case, the finite-sample coverage properties of such intervals are determined and it is shown that symmetric intervals are the shortest. The length of the shortest intervals based on the hard-thresholding estimator is larger than the length of the shortest interval based on the adaptive LASSO, which is larger than the length of the shortest interval based on the LASSO, which in turn is larger than the standard interval based on the maximum likelihood estimator. In the case where the penalized estimators are tuned to possess the `sparsity property', the intervals based on these estimators are larger than the standard interval by an order of magnitude. Furthermore, a simple asymptotic confidence interval construction in the `sparse' case, that also applies to the smoothly clipped absolute deviation estimator, is discussed. The results for the known-variance case are shown to carry over to the unknown-variance case in an appropriate asymptotic sense.},
  keywords = {62C25,62F25,62J07,Adaptive LASSO,confidence set,coverage probability,hard-thresholding,Lasso,Model selection,penalized least squares,penalized maximum likelihood,soft-thresholding,Sparsity}
  }


@article{whittingham_why_2006,
	title = {Why do we still use stepwise modelling in ecology and behaviour?},
	volume = {75},
	number = {5},
	journal = {Journal of Animal Ecology},
	author = {Whittingham, Mark J. and Stephens, Philip A. and Bradbury, Richard B. and Freckleton, Robert P.},
	year = {2006},
	pages = {1182--1189},
doi = {10.1111/j.1365-2656.2006.01141.x}
}


@book{harrell_regression_2001,
	title = {Regression {Modeling} {Strategies}},
	isbn = {0-387-95232-2},
	publisher = {Springer},
	author = {Harrell, Frank},
	year = {2001}
}


@article{murtaugh_performance_2009,
	title = {Performance of several variable-selection methods applied to real ecological data},
	volume = {12},
	issn = {1461023X, 14610248},
	url = {http://doi.wiley.com/10.1111/j.1461-0248.2009.01361.x},
	doi = {10.1111/j.1461-0248.2009.01361.x},
	language = {en},
	number = {10},
	urldate = {2015-07-11},
	journal = {Ecology Letters},
	author = {Murtaugh, Paul A.},
	year = {2009},
	pages = {1061--1068}
}

@article{brando_fire-induced_2012,
  title={Fire-induced tree mortality in a neotropical forest: the roles of bark traits, tree size, wood density and fire behavior},
  author={Brando, P.M. and Nepstad, D.C. and Balch, J.K. and Bolker, B. and Christman, M.C. and Coe, M. and Putz, F.E.},
  journal={Global Change Biology},
  volume={18},
  number={2},
  pages={630--641},
  year={2012},
  pdf={bbpapers/brando_fire-induced_2012.pdf},
  doi={10.1111/j.1365-2486.2011.02533.x}
}

@article{ghenu_multicopy_2016,
	title = {Multicopy gene family evolution on primate {Y} chromosomes},
	volume = {17},
	issn = {1471-2164},
	url = {http://dx.doi.org/10.1186/s12864-015-2187-8},
	doi = {10.1186/s12864-015-2187-8},
	abstract = {The primate Y chromosome is distinguished by a lack of inter-chromosomal recombination along most of its length, extensive gene loss, and a prevalence of repetitive elements. A group of genes on the male-specific portion of the Y chromosome known as the “ampliconic genes” are present in multiple copies that are sometimes part of palindromes, and that undergo a form of intra-chromosomal recombination called gene conversion, wherein the nucleotides of one copy are homogenized by those of another. With the aim of further understanding gene family evolution of these genes, we collected nucleotide sequence and gene copy number information for several species of papionin monkey. We then tested for evidence of gene conversion, and developed a novel statistical framework to evaluate alternative models of gene family evolution using our data combined with other information from a human, a chimpanzee, and a rhesus macaque.},
	urldate = {2016-08-03},
	journal = {BMC Genomics},
	author = {Ghenu, Ana-Hermina and Bolker, Benjamin M. and Melnick, Don J. and Evans, Ben J.},
	year = {2016},
	keywords = {Ampliconic genes, Gene conversion, Gene duplication, Gene family evolution, Genome structure, Great apes, Old World Monkeys, Y chromosome},
	pages = {157},
	annote = {Pages 1-17 in PDF},
	file = {Full Text PDF:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/S2N7AMKI/Ghenu et al. - 2016 - Multicopy gene family evolution on primate Y chrom.pdf:application/pdf;Snapshot:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/Z4EXFQJE/s12864-015-2187-8.html:text/html}
}

@ARTICLE{Gruner+2008,
  author = {Gruner, D. S. and Smith, J. E. and Seabloom, E. W. and Sandin, S.
	A. and Ngai, J. T. and Hillebrand, H. and Harpole, W. S. and Elser,
	J. J. and Cleland, E. E. and Bracken, M. E. S. and Borer, E. T. and
	Bolker, B. M.},
  title = {A cross-system synthesis of consumer and nutrient resource control
	on producer biomass},
  journal = {Ecology Letters},
  year = {2008},
  volume = {11},
  pages = {740--755},
  number = {7},
  SN = {1461-023X},
  TC = {0},
  UT = {MEDLINE:18445030},
  owner = {ben},
  timestamp = {2008.08.01}
}

@Book{BurnAnde98,
  Author         = {Burnham, Kenneth P. and Anderson, David R.},
  Title          = {Model Selection and Inference: A Practical
                   Information-Theoretic Approach},
  Publisher      = {Springer},
  Address        = {New York},
  year           = 1998
}


@book{burnham_model_2002,
	title = {Model {Selection} and {Multimodel} {Inference}: {A} {Practical} {Information}-theoretic {Approach}},
	isbn = {978-0-387-95364-9},
	shorttitle = {Model {Selection} and {Multimodel} {Inference}},
	abstract = {The second edition of this book is unique in that it focuses on methods for making formal statistical inference from all the models in an a priori set (Multi-Model Inference). A philosophy is presented for model-based data analysis and a general strategy outlined for the analysis of empirical data. The book invites increased attention on a priori science hypotheses and modeling.Kullback-Leibler Information represents a fundamental quantity in science and is Hirotugu Akaike's basis for model selection. The maximized log-likelihood function can be bias-corrected as an estimator of expected, relative Kullback-Leibler information. This leads to Akaike's Information Criterion (AIC) and various extensions. These methods are relatively simple and easy to use in practice, but based on deep statistical theory. The information theoretic approaches provide a unified and rigorous theory, an extension of likelihood theory, an important application of information theory, and are objective and practical to employ across a very wide class of empirical problems.The book presents several new ways to incorporate model selection uncertainty into parameter estimates and estimates of precision. An array of challenging examples is given to illustrate various technical issues.This is an applied book written primarily for biologists and statisticians wanting to make inferences from multiple models and is suitable as a graduate text or as a reference for professional analysts.},
	language = {en},
	publisher = {Springer},
	author = {Burnham, Kenneth P. and Anderson, David R.},
	year = {2002},
	keywords = {biology, Biology/ Mathematical models, Biology - Mathematical models, Mathematical statistics, Mathematics / General, Mathematics / Probability \& Statistics / General, Medical / Biostatistics, Science / General, Science / Life Sciences / Biology}
}

@article{fieberg_mmi_2015,
	title = {{MMI}: {Multimodel} inference or models with management implications?: {Multimodel} {Inference} and {Models} for {Management}},
	volume = {79},
	issn = {0022541X},
	shorttitle = {{MMI}},
	url = {http://doi.wiley.com/10.1002/jwmg.894},
	doi = {10.1002/jwmg.894},
	language = {en},
	number = {5},
	urldate = {2017-04-23},
	journal = {The Journal of Wildlife Management},
	author = {Fieberg, John and Johnson, Douglas H.},
	year = {2015},
	pages = {708--718}
}

@article{galipaud_ecologists_2014,
	title = {Ecologists overestimate the importance of predictor variables in model averaging: a plea for cautious interpretations},
	volume = {5},
	issn = {2041-210X},
	shorttitle = {Ecologists overestimate the importance of predictor variables in model averaging},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12251/abstract},
	doi = {10.1111/2041-210X.12251},
	abstract = {* Information-theory procedures are powerful tools for multimodel inference and are now standard methods in ecology. When performing model averaging on a given set of models, the importance of a predictor variable is commonly estimated by summing the weights of models where the variable appears, the so-called sum of weights (SW). However, SWs have received little methodological attention and are frequently misinterpreted.


* We assessed the reliability of SW by performing model selection and averaging on simulated data sets including variables strongly and weakly correlated to the response variable and a variable unrelated to the response. Our aim was to investigate how useful SWs are to inform about the relative importance of predictor variables.


* SW can take a wide range of possible values, even for predictor variables unrelated to the response. As a consequence, SW with intermediate values cannot be confidently interpreted as denoting importance for the considered predictor variable. Increasing sample size using an alternative information criterion for model selection or using only a subset of candidate models for model averaging did not qualitatively change our results: a variable of a given effect size can take a wide range of SW values.


* Contrary to what is assumed in many ecological studies, it seems hazardous to define a threshold for SW above which a variable is considered as having a statistical effect on the response and SW is not a measure of effect size. Although we did not consider every possible condition of analysis, it is likely that in most situations, SW is a poor estimate of variable's importance.},
	language = {en},
	number = {10},
	urldate = {2016-08-12},
	journal = {Methods in Ecology and Evolution},
	author = {Galipaud, Matthias and Gillingham, Mark A. F. and David, Morgan and Dechaume-Moncharmont, François-Xavier},
	year = {2014},
	keywords = {Akaike Information Criterion, baseline sum of weights, Bayesian information criterion, information theory, model averaging, model selection, multimodel inference, variable importance},
	pages = {983--991}
}


@Article{freckleton_dealing_2011,
  author = 	 {Robert P. Freckleton},
  title = 	 {Dealing with collinearity in behavioural and ecological data: model averaging and the problems of measurement error},
  journal = 	 {Behavioral Ecology and Sociobiology},
  year = 	 {2011},
  volume =	 {65},
  number =	 {1},
  pages =	 {91-101}
}


@article{wenger_assessing_2012,
	Author = {Wenger, Seth J. and Olden, Julian D.},
	Doi = {10.1111/j.2041-210X.2011.00170.x},
	Issn = {2041210X},
	Journal = {Methods in Ecology and Evolution},
	Number = {2},
	Pages = {260--267},
	Shorttitle = {Assessing transferability of ecological models},
	Title = {Assessing transferability of ecological models: an underappreciated aspect of statistical validation},
	Url = {http://doi.wiley.com/10.1111/j.2041-210X.2011.00170.x},
	Urldate = {2013-06-29},
	Volume = {3},
	Year = {2012}}

@Article{obenchain_classical_1977,
  author = 	 {Obenchain, R.},
  title = 	 {Classical $F$-Tests and Confidence Regions for Ridge Regression},
  journal = 	 {Technometrics},
  year = 	 {1977},
  volume =	 {19},
  number =	 {4},
  pages =	 {429-439}
}

@article{turek2012model,
  title={Model-averaged Wald confidence intervals},
  author={Turek, Daniel and Fletcher, David},
  journal={Computational Statistics \& Data Analysis},
  volume={56},
  number={9},
  pages={2809--2815},
  year={2012},
doi = {10.1016/j.csda.2012.03.002}
}

@article{turek2015comparison,
  title={Comparison of the Frequentist {MATA} Confidence Interval with {Bayesian} Model-Averaged Confidence Intervals},
  author={Turek, Daniel},
  journal={Journal of Probability and Statistics},
  volume={2015},
  year={2015},
doi = { 10.1155/2015/420483}
}

@phdthesis{turek2013frequentist,
  title={Frequentist model-averaged confidence intervals},
  author={Turek, Daniel Bernard},
  url={https://www.otago.ourarchive.ac.nz/bitstream/handle/10523/3923/TurekDanielB2013PhD.pdf},
  year={2013},
  school={University of Otago}
}

@article{fletcher2012model,
  title={Model-averaged profile likelihood intervals},
  author={Fletcher, David and Turek, Daniel},
  journal={Journal of agricultural, biological, and environmental statistics},
  volume={17},
  number={1},
  pages={38--51},
  year={2012},
  publisher={Springer}
}

@article{taper_evidential_2015,
	title = {Evidential statistics as a statistical modern synthesis to support 21st century science},
	volume = {58},
	issn = {1438-3896, 1438-390X},
	url = {http://link.springer.com/article/10.1007/s10144-015-0533-y},
	doi = {10.1007/s10144-015-0533-y},
	abstract = {During the 20th century, population ecology and science in general relied on two very different statistical paradigms to solve its inferential problems: error statistics (also referred to as classical statistics and frequentist statistics) and Bayesian statistics. A great deal of good science was done using these tools, but both schools suffer from technical and philosophical difficulties. At the turning of the 21st century (Royall in Statistical evidence: a likelihood paradigm. Chapman \& Hall, London, 1997; Lele in The nature of scientific evidence: statistical, philosophical and empirical considerations. The University of Chicago Press, Chicago, pp 191–216, 2004a), evidential statistics emerged as a seriously contending paradigm. Drawing on and refining elements from error statistics, likelihoodism, Bayesian statistics, information criteria, and robust methods, evidential statistics is a statistical modern synthesis that smoothly incorporates model identification, model uncertainty, model comparison, parameter estimation, parameter uncertainty, pre-data control of error, and post-data strength of evidence into a single coherent framework. We argue that evidential statistics is currently the most effective statistical paradigm to support 21st century science. Despite the power of the evidential paradigm, we think that there is no substitute for learning how to clarify scientific arguments with statistical arguments. In this paper we sketch and relate the conceptual bases of error statistics, Bayesian statistics and evidential statistics. We also discuss a number of misconceptions about the paradigms that have hindered practitioners, as well as some real problems with the error and Bayesian statistical paradigms solved by evidential statistics.},
	language = {en},
	number = {1},
	urldate = {2016-09-07},
	journal = {Population Ecology},
	author = {Taper, Mark L. and Ponciano, José Miguel},
	year = {2015},
	pages = {9--29},
	file = {Snapshot:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/KZXKPZA8/s10144-015-0533-y.html:text/html}
}

@article{walker_defense_2017,
	title = {A Defense Of Model Averaging},
	copyright = {© 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	 url = {http://biorxiv.org/content/early/2017/05/03/133785},
       doi = {10.1101/133785},
       abstract = {Model averaging of partial regression coefficients has been criticized for averaging over a set of models with coefficients that are either incommensurable or describe fundamentally different things if there is any correlation (multicollinearity) among the predictors. It is easy to show that partial regression coefficients conditional on different covariates are commensurable. And, partial regression coefficients from different models can have the same meaning if they are used to estimate the effects in a causal model, which derive their meaning from the specified paths and not from the set of covariates. A multiple regression model implicitly specifies a causal model with direct, causal paths from each predictor to the response. Consequently, the partial regression coefficient for a predictor has the same meaning across all sub-models if the goal is estimation of the causal effects that generated the response. In order to clarify the effects of multicollinearity on model-averaged estimates, I compare effect estimates using a small Monte-Carlo simulation. The simulation results show that model-averaged and ridge estimates have increasingly better performance, relative to model selection and full model estimates, as multicollinearity increases.},
	language = {en},
	urldate = {2017-06-02},
	journal = {bioRxiv},
	author = {Walker, Jeffrey A.},
	year = {2017},
	pages = {133785}
}

@techreport{nilsen_confidence_2005,
	type = {Working paper},
	title = {Confidence intervals for the shrinkage estimator},
	url = {https://brage.bibsys.no/xmlui/handle/11250/165518},
	abstract = {Shrinkage estimators have recently become popular in estimation of heterogeneous models on panel data. In this chapter we show that the estimated covariance matrix in the posterior distribution of the shrinkage estimator fails to include the variability of the hyperparameters. Hence, standard confidence intervals for the parameters based on the “estimated posterior” distribution, are too narrow and thus the t-statistic is upward biased. The bootstrap method, which incorporates some of the variability in the hyperparameters, is an alternative method to obtain confidence intervals for the parameters. Our empirical example shows that one has to be aware of the method used, since it can lead to significantly different economic conclusions.},
	language = {eng},
	urldate = {2017-06-02},
	institution = {SNF},
	author = {Nilsen, Odd Bjarte and Asche, Frank and Tveterås, Ragnar},
	year = 2005
}

@article{lukacs_model_2010,
	title = {Model selection bias and {Freedman}’s paradox},
	volume = {62},
	issn = {0020-3157, 1572-9052},
	url = {http://link.springer.com/10.1007/s10463-009-0234-4},
	doi = {10.1007/s10463-009-0234-4},
	language = {en},
	number = {1},
	urldate = {2017-06-02},
	journal = {Annals of the Institute of Statistical Mathematics},
	author = {Lukacs, Paul M. and Burnham, Kenneth P. and Anderson, David R.},
	year = {2010},
	pages = {117--125}
}


@article{zhang_model_2015,
	title = {Model averaging based on {Kullback}-{Leibler} distance},
	volume = {25},
	issn = {1017-0405},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5066877/},
	doi = {10.5705/ss.2013.326},
	abstract = {This paper proposes a model averaging method based on Kullback-Leibler distance under a homoscedastic normal error term. The resulting model average estimator is proved to be asymptotically optimal. When combining least squares estimators, the model average estimator is shown to have the same large sample properties as the Mallows model average (MMA) estimator developed by . We show via simulations that, in terms of mean squared prediction error and mean squared parameter estimation error, the proposed model average estimator is more efficient than the MMA estimator and the estimator based on model selection using the corrected Akaike information criterion in small sample situations. A modified version of the new model average estimator is further suggested for the case of heteroscedastic random errors. The method is applied to a data set from the Hong Kong real estate market.},
	urldate = {2017-06-02},
	journal = {Statistica Sinica},
	author = {Zhang, Xinyu and Zou, Guohua and Carroll, Raymond J.},
	year = {2015},
	pmid = {27761098},
	pmcid = {PMC5066877},
	pages = {1583--1598}
}


@article{kabaila_model-averaged_2016,
	title = {Model-{Averaged} {Confidence} {Intervals}},
	volume = {43},
	issn = {1467-9469},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/sjos.12163/abstract},
	doi = {10.1111/sjos.12163},
	abstract = {We develop an approach to evaluating frequentist model averaging procedures by considering them in a simple situation in which there are two-nested linear regression models over which we average. We introduce a general class of model averaged confidence intervals, obtain exact expressions for the coverage and the scaled expected length of the intervals, and use these to compute these quantities for the model averaged profile likelihood (MPI) and model-averaged tail area confidence intervals proposed by D. Fletcher and D. Turek. We show that the MPI confidence intervals can perform more poorly than the standard confidence interval used after model selection but ignoring the model selection process. The model-averaged tail area confidence intervals perform better than the MPI and postmodel-selection confidence intervals but, for the examples that we consider, offer little over simply using the standard confidence interval for θ under the full model, with the same nominal coverage.},
	language = {en},
	number = {1},
	urldate = {2017-06-02},
	journal = {Scandinavian Journal of Statistics},
	author = {Kabaila, Paul and Welsh, A. H. and Abeysekera, Waruni},
	year = {2016},
	keywords = {Akaike Information Criterion, Confidence Interval, coverage probability, expected length, model selection, nominal coverage, Profile likelihood, regression models, tail area confidence interval},
	pages = {35--48}
}


@book{claeskens_model_2008,
	series = {Cambridge {Series} in {Statistical} and {Probabilistic} {Mathematics}},
	title = {Model {Selection} and {Model} {Averaging}},
	isbn = {978-0-521-85225-8},
	urldate = {2017-06-27},
	publisher = {Cambridge University Press},
	author = {Claeskens, Gerda and Hjort, Nils Lid},
	year = {2008}
}



@article{raup_method_1995,
	title = {The {Method} of {Multiple} {Working} {Hypotheses}},
	volume = {103},
	url = {http://www.jstor.org/stable/30071227},
	number = {3},
	urldate = {2016-08-11},
	journal = {The Journal of Geology},
	author = {Raup, David C. and Chamberlin, T. C.},
	year = {1995},
	pages = {349--354}
}



@article{hooten_guide_2015,
	title = {A guide to {Bayesian} model selection for ecologists},
	volume = {85},
	issn = {0012-9615},
	url = {http://www.jstor.org/stable/24818229},
	abstract = {The steady upward trend in the use of model selection and Bayesian methods in ecological research has made it clear that both approaches to inference are important for modern analysis of models and data. However, in teaching Bayesian methods and in working with our research colleagues, we have noticed a general dissatisfaction with the available literature on Bayesian model selection and multimodel inference. Students and researchers new to Bayesian methods quickly find that the published advice on model selection is often preferential in its treatment of options for analysis, frequently advocating one particular method above others. The recent appearance of many articles and textbooks on Bayesian modeling has provided welcome background on relevant approaches to model selection in the Bayesian framework, but most of these are either very narrowly focused in scope or inaccessible to ecologists. Moreover, the methodological details of Bayesian model selection approaches are spread thinly throughout the literature, appearing in journals from many different fields. Our aim with this guide is to condense the large body of literature on Bayesian approaches to model selection and multimodel inference and present it specifically for quantitative ecologists as neutrally as possible. We also bring to light a few important and fundamental concepts relating directly to model selection that seem to have gone unnoticed in the ecological literature. Throughout, we provide only a minimal discussion of philosophy, preferring instead to examine the breadth of approaches as well as their practical advantages and disadvantages. This guide serves as a reference for ecologists using Bayesian methods, so that they can better understand their options and can make an informed choice that is best aligned with their goals for inference.},
	number = {1},
	urldate = {2018-01-05},
	journal = {Ecological Monographs},
	author = {Hooten, M. B. and Hobbs, N. T.},
	year = {2015},
	pages = {3--28}
}


@article{van_houwelingen_shrinkage_2001,
	title = {Shrinkage and {Penalized} {Likelihood} as {Methods} to {Improve} {Predictive} {Accuracy}},
	volume = {55},
	issn = {0039-0402},
	url = {http://journals.scholarsportal.info/details/00390402/v55i0001/17_saplamtipa.xml},
	doi = {10.1111/1467-9574.00154},
	abstract = {A review is given of shrinkage and penalization as tools to improve predictive accuracy of regression models. The James-Stein estimator is taken as starting point. Procedures covered are Pre-test Estimation, the Ridge Regression of Hoerl and Kennard, the Shrinkage Estimators of Copas and Van Houwelingen and Le Cessie, the LASSO of Tibshirani and the Garotte of Breiman. An attempt is made to place all these procedures in a unifying framework of semi-Bayesian methodology. Applications are briefly mentioned, but not amply discussed.},
	number = {1},
	urldate = {2018-01-05},
	journal = {Statistica Neerlandica},
	author = {{van Houwelingen}, J. C},
	year = {2001},
	keywords = {Garotte, LASSO, Pre-test Estimation, Ridge Regression},
	pages = {17--34}
}


@article{dormann_model_2018,
	title = {Model averaging in ecology: a review of {Bayesian}, information-theoretic and tactical approaches for predictive inference},
	issn = {0012-9615},
	shorttitle = {Model averaging in ecology},
	url = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecm.1309},
	doi = {10.1002/ecm.1309},
	abstract = {Abstract In ecology, the true causal structure for a given problem is often not known, and several plausible models and thus model predictions exist. It has been claimed that using weighted averages of these models can reduce prediction error, as well as better reflect model selection uncertainty. These claims, however, are often demonstrated by isolated examples. Analysts must better understand under which conditions model averaging can improve predictions and their uncertainty estimates. Moreover, a large range of different model averaging methods exists, raising the question of how they differ regarding in their behaviour and performance. Here, we review the mathematical foundations of model averaging along with the diversity of approaches available. We explain that the error in model?averaged predictions depends on each model's predictive bias and variance, as well as the covariance in predictions between models and uncertainty about model weights. We show that model averaging is particularly useful if the predictive error of contributing model predictions is dominated by variance, and if the covariance between models is low. For noisy data, which predominate in ecology, these conditions will often be met. Many different methods to derive averaging weights exist, from from Bayesian over information?theoretical to cross?validation optimised and resampling approaches. A general recommendation is difficult, because the performance of methods is often context?dependent. Importantly, estimating weights creates some additional uncertainty. As a result, estimated model weights may not always outperform arbitrary fixed weights, such as equal weights for all models. When averaging a set of models with many inadequate models, however, estimating model weights will typically be superior to equal weights. We also investigate the quality of the confidence intervals calculated for model?averaged predictions, showing that they differ greatly in behaviour and seldom manage to achieve nominal coverage. Our overall recommendations stress the importance of non?parametric methods such as cross?validation for a reliable uncertainty quantification of model?averaged predictions. This article is protected by copyright. All rights reserved.},
	urldate = {2018-05-19},
	journal = {Ecological Monographs},
	author = {Dormann, Carsten F. and Calabrese, Justin M. and Guillera-Arroita, Gurutzeta and Matechou, Eleni and Bahn, Volker and Bartoń, Kamil and Beale, Colin M. and Ciuti, Simone and Elith, Jane and Gerstner, Katharina and Guelat, Jérôme and Keil, Petr and Lahoz-Monfort, José J. and Pollock, Laura J. and Reineking, Björn and Roberts, David R. and Schröder, Boris and Thuiller, Wilfried and Warton, David I. and Wintle, Brendan A. and Wood, Simon N. and Wüest, Rafael O. and Hartig, Florian},
	year = {2018},
	keywords = {uncertainty, model averaging, nominal coverage, AIC-weights, ensemble, model combination, prediction averaging}
}


@article{betini_why_2017,
	title = {Why are we not evaluating multiple competing hypotheses in ecology and evolution?},
	volume = {4},
	copyright = {© 2017 The Authors.. Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the original author and source are credited.},
	issn = {2054-5703},
	url = {http://rsos.royalsocietypublishing.org/content/4/1/160756},
	doi = {10.1098/rsos.160756},
	abstract = {The use of multiple working hypotheses to gain strong inference is widely promoted as a means to enhance the effectiveness of scientific investigation. Only 21 of 100 randomly selected studies from the ecological and evolutionary literature tested more than one hypothesis and only eight tested more than two hypotheses. The surprising rarity of application of multiple working hypotheses suggests that this gap between theory and practice might reflect some fundamental issues. Here, we identify several intellectual and practical barriers that discourage us from using multiple hypotheses in our scientific investigation. While scientists have developed a number of ways to avoid biases, such as the use of double-blind controls, we suspect that few scientists are fully aware of the potential influence of cognitive bias on their decisions and they have not yet adopted many techniques available to overcome intellectual and practical barriers in order to improve scientific investigation.},
	language = {en},
	number = {1},
	urldate = {2017-01-11},
	journal = {Royal Society Open Science},
	author = {Betini, Gustavo S. and Avgar, Tal and Fryxell, John M.},
	year = {2017},
	pages = {16056}
}


@article{jones_sensible_2000,
	title = {A {Sensible} {Formulation} of the {Significance} {Test}},
	volume = {5},
	issn = {1082-989x},
	url = {http://journals.scholarsportal.info/details/1082989x/v05i0004/411_asfotst.xml},
	doi = {10.1037//1082-989X.5.4.411},
	abstract = {The conventional procedure for null hypothesis significance testing has long been the target of appropriate criticism. A more reasonable alternative is proposed, one that not only avoids the unrealistic postulation of a null hypothesis but also, for a given parametric difference and a given error probability, is more likely to report the detection of that difference.},
	number = {4},
	urldate = {2018-05-20},
	journal = {Psychological Methods},
	author = {Jones, Lyle V. and Tukey, John W.},
	year = {2000},
	pages = {411--414}
}


@article{elliott_revisiting_2007,
	title = {Revisiting {Chamberlin}: {Multiple} {Working} {Hypotheses} for the 21st {Century}},
	volume = {57},
	issn = {0006-3568},
	shorttitle = {Revisiting {Chamberlin}},
	url = {https://academic.oup.com/bioscience/article/57/7/608/238555},
	doi = {10.1641/B570708},
	abstract = {Abstract.  The method of multiple working hypotheses, developed by the 19th-century geologist T. C. Chamberlin, is an important philosophical contribution to th},
	language = {en},
	number = {7},
	urldate = {2018-06-21},
	journal = {BioScience},
	author = {Elliott, Louis P. and Brook, Barry W.},
	year = {2007},
	pages = {608--614}
}


@misc{hardy_machine_2017,
	title = {machine learning - {Speed}, computational expenses of {PCA}, {LASSO}, elastic net},
	url = {https://stats.stackexchange.com/questions/177665/speed-computational-expenses-of-pca-lasso-elastic-net},
	urldate = {2018-06-23},
	journal = {Cross Validated},
	author = {Hardy, Richard},
	year = {2017}
}


@phdthesis{louppe_understanding_2014,
	address = {Faculty of Applied Sciences, Department of Electrical Engineering \& Computer Science},
	type = {{PhD} {Thesis}},
	title = {Understanding random forests: {From} theory to practice},
	shorttitle = {Understanding random forests},
	url = {https://arxiv.org/pdf/1407.7502},
	school = {University of Liège},
	author = {Louppe, Gilles},
	year = {2014}
}


@article{crome_novel_1996,
	title = {A {Novel} {Bayesian} {Approach} to {Assessing} {Impacts} of {Rain} {Forest} {Logging}},
	volume = {6},
	journal = {Ecological Applications},
	author = {Crome, F. H. J. and Thomas, M. R. and Moore, L. A.},
	year = {1996},
	pages = {1104--1123}
}


@article{schomaker_when_2018,
	title = {When and when not to use optimal model averaging},
	issn = {1613-9798},
	url = {https://doi.org/10.1007/s00362-018-1048-3},
	doi = {10.1007/s00362-018-1048-3},
	abstract = {Traditionally model averaging has been viewed as an alternative to model selection with the ultimate goal to incorporate the uncertainty associated with the model selection process in standard errors and confidence intervals by using a weighted combination of candidate models. In recent years, a new class of model averaging estimators has emerged in the literature, suggesting to combine models such that the squared risk, or other risk functions, are minimized. We argue that, contrary to popular belief, these estimators do not necessarily address the challenges induced by model selection uncertainty, but should be regarded as attractive complements for the machine learning and forecasting literature, as well as tools to identify causal parameters. We illustrate our point by means of several targeted simulation studies.},
	language = {en},
	urldate = {2018-11-25},
	journal = {Statistical Papers},
	author = {Schomaker, Michael and Heumann, Christian},
	month = sep,
	year = {2018},
	keywords = {Causal inference, Machine learning, Model averaging, Model selection, Prediction}
}


@book{fletcher_model_2018,
	address = {Berlin Heidelberg},
	series = {{SpringerBriefs} in {Statistics}},
	title = {Model {Averaging}},
	isbn = {978-3-662-58540-5},
	url = {//www.springer.com/us/book/9783662585405},
	abstract = {This book provides a concise and accessible overview of model averaging, with a focus on applications. Model averaging is a common means of allowing for model uncertainty when analysing data, and has been used in a wide range of application areas, such as ecology, econometrics, meteorology and pharmacology. The book presents an overview of the methods developed in this area, illustrating many of them with examples from the life sciences involving real-world data. It also includes an extensive list of references and suggestions for further research. Further, it clearly demonstrates the links between the methods developed in statistics, econometrics and machine learning, as well as the connection between the Bayesian and frequentist approaches to model averaging. The book appeals to statisticians and scientists interested in what methods are available, how they differ and what is known about their properties. It is assumed that readers are familiar with the basic concepts of statistical theory and modelling, including probability, likelihood and generalized linear models.},
	language = {en},
	urldate = {2018-11-25},
	publisher = {Springer-Verlag},
	author = {Fletcher, David},
	year = {2018}
}


@article{fletcher_model-averaged_2011,
	title = {Model-averaged confidence intervals for factorial experiments},
	volume = {55},
	issn = {01679473},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167947311001800},
	doi = {10.1016/j.csda.2011.05.014},
	language = {en},
	number = {11},
	urldate = {2015-07-06},
	journal = {Computational Statistics \& Data Analysis},
	author = {Fletcher, David and Dillingham, Peter W.},
	month = nov,
	year = {2011},
	pages = {3041--3048}
}


@article{dezeure_high-dimensional_2015,
	title = {High-{Dimensional} {Inference}: {Confidence} {Intervals}, \$p\$-{Values} and {R}-{Software} hdi},
	volume = {30},
	issn = {0883-4237, 2168-8745},
	shorttitle = {High-{Dimensional} {Inference}},
	url = {https://projecteuclid.org/euclid.ss/1449670857},
	doi = {10.1214/15-STS527},
	abstract = {We present a (selective) review of recent frequentist high-dimensional inference methods for constructing ppp-values and confidence intervals in linear and generalized linear models. We include a broad, comparative empirical study which complements the viewpoint from statistical methodology and theory. Furthermore, we introduce and illustrate the R-package hdi which easily allows the use of different methods and supports reproducibility.},
	language = {EN},
	number = {4},
	urldate = {2019-01-09},
	journal = {Statistical Science},
	author = {Dezeure, Ruben and Bühlmann, Peter and Meier, Lukas and Meinshausen, Nicolai},
	month = nov,
	year = {2015},
	mrnumber = {MR3432840},
	zmnumber = {06946201},
	keywords = {\$p\$-value, Clustering, confidence interval, generalized linear model, high-dimensional statistical inference, linear model, multiple testing, R-software},
	pages = {533--558}
}


@article{fithian_optimal_2017,
	title = {Optimal {Inference} {After} {Model} {Selection}},
	url = {http://arxiv.org/abs/1410.2597},
	abstract = {To perform inference after model selection, we propose controlling the selective type I error; i.e., the error rate of a test given that it was performed. By doing so, we recover long-run frequency properties among selected hypotheses analogous to those that apply in the classical (non-adaptive) context. Our proposal is closely related to data splitting and has a similar intuitive justification, but is more powerful. Exploiting the classical theory of Lehmann and Scheff{\textbackslash}'e (1955), we derive most powerful unbiased selective tests and confidence intervals for inference in exponential family models after arbitrary selection procedures. For linear regression, we derive new selective z-tests that generalize recent proposals for inference after model selection and improve on their power, and new selective t-tests that do not require knowledge of the error variance.},
	urldate = {2019-01-09},
	journal = {arXiv:1410.2597 [math, stat]},
	author = {Fithian, William and Sun, Dennis and Taylor, Jonathan},
	month = apr,
	year = {2017},
	note = {arXiv: 1410.2597},
	keywords = {Mathematics - Statistics Theory, Statistics - Methodology}
}


@book{crawley_statistics_2011,
	title = {Statistics: {An} {Introduction} using {R}},
	isbn = {978-0-470-02299-3},
	shorttitle = {Statistics},
	abstract = {Computer software is an essential tool for many statistical modelling and data analysis techniques, aiding in the implementation of large data sets in order to obtain useful results. R is one of the most powerful and flexible statistical software packages available, and enables the user to apply a wide variety of statistical methods ranging from simple regression to generalized linear modelling. Statistics: An Introduction using R is a clear and concise introductory textbook to statistical analysis using this powerful and free software, and follows on from the success of the author's previous best-selling title Statistical Computing.* Features step-by-step instructions that assume no mathematics, statistics or programming background, helping the non-statistician to fully understand the methodology.* Uses a series of realistic examples, developing step-wise from the simplest cases, with the emphasis on checking the assumptions (e.g. constancy of variance and normality of errors) and the adequacy of the model chosen to fit the data.* The emphasis throughout is on estimation of effect sizes and confidence intervals, rather than on hypothesis testing.* Covers the full range of statistical techniques likely to be need to analyse the data from research projects, including elementary material like t-tests and chi-squared tests, intermediate methods like regression and analysis of variance, and more advanced techniques like generalized linear modelling.* Includes numerous worked examples and exercises within each chapter.* Accompanied by a website featuring worked examples, data sets, exercises and solutions:http://www.imperial.ac.uk/bio/research/crawley/statisticsStatistics: An Introduction using R is the first text to offer such a concise introduction to a broad array of statistical methods, at a level that is elementary enough to appeal to a broad range of disciplines. It is primarily aimed at undergraduate students in medicine, engineering, economics and biology - but will also appeal to postgraduates who have not previously covered this area, or wish to switch to using R.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Crawley, Michael J.},
	month = dec,
	year = {2011},
	keywords = {Mathematics / Probability \& Statistics / General}
}


@book{zuur_mixed_2009,
	edition = {1},
	title = {Mixed {Effects} {Models} and {Extensions} in {Ecology} with {R}},
	isbn = {0-387-87457-7},
	publisher = {Springer},
	author = {Zuur, Alain F. and Ieno, Elena N. and Walker, Neil J. and Saveliev, Anatoly A. and Smith, Graham M.},
	month = mar,
	year = {2009}
}


@book{quinn_experimental_2002,
	address = {Cambridge, England},
	title = {Experimental {Design} and {Data} {Analysis} for {Biologists}},
	isbn = {0-521-00976-6},
	publisher = {Cambridge University Press},
	author = {Quinn, Gerry P. and Keough, Michael J.},
	year = {2002}
}


@article{zhao_defense_2017,
	title = {In {Defense} of the {Indefensible}: {A} {Very} {Naive} {Approach} to {High}-{Dimensional} {Inference}},
	shorttitle = {In {Defense} of the {Indefensible}},
	url = {http://arxiv.org/abs/1705.05543},
	abstract = {In recent years, a great deal of interest has focused on conducting inference on the parameters in a linear model in the high-dimensional setting. In this paper, we consider a simple and very na{\textbackslash}"\{i\}ve two-step procedure for this task, in which we (i) fit a lasso model in order to obtain a subset of the variables; and (ii) fit a least squares model on the lasso-selected set. Conventional statistical wisdom tells us that we cannot make use of the standard statistical inference tools for the resulting least squares model (such as confidence intervals and \$p\$-values), since we peeked at the data twice: once in running the lasso, and again in fitting the least squares model. However, in this paper, we show that under a certain set of assumptions, with high probability, the set of variables selected by the lasso is deterministic. Consequently, the na{\textbackslash}"\{i\}ve two-step approach can yield confidence intervals that have asymptotically correct coverage, as well as p-values with proper Type-I error control. Furthermore, this two-step approach unifies two existing camps of work on high-dimensional inference: one camp has focused on inference based on a sub-model selected by the lasso, and the other has focused on inference using a debiased version of the lasso estimator.},
	urldate = {2020-03-11},
	journal = {arXiv:1705.05543 [math, stat]},
	author = {Zhao, Sen and Shojaie, Ali and Witten, Daniela},
	month = dec,
	year = {2017},
	note = {arXiv: 1705.05543},
	keywords = {Mathematics - Statistics Theory, Statistics - Machine Learning, Statistics - Methodology},
	annote = {Comment: 61 pages, 3 figures, 8 tables}
}



@article{richards_model_2011,
	title = {Model selection and model averaging in behavioural ecology: the utility of the {IT}-{AIC} framework},
	volume = {65},
	issn = {1432-0762},
	shorttitle = {Model selection and model averaging in behavioural ecology},
	url = {https://doi.org/10.1007/s00265-010-1035-8},
	doi = {10.1007/s00265-010-1035-8},
	abstract = {Behavioural ecologists often study complex systems in which multiple hypotheses could be proposed to explain observed phenomena. For some systems, simple controlled experiments can be employed to reveal part of the complexity; often, however, observational studies that incorporate a multitude of causal factors may be the only (or preferred) avenue of study. We assess the value of recently advocated approaches to inference in both contexts. Specifically, we examine the use of information theoretic (IT) model selection using Akaike’s information criterion (AIC). We find that, for simple analyses, the advantages of switching to an IT-AIC approach are likely to be slight, especially given recent emphasis on biological rather than statistical significance. By contrast, the model selection approach embodied by IT approaches offers significant advantages when applied to problems of more complex causality. Model averaging is an intuitively appealing extension to model selection. However, we were unable to demonstrate consistent improvements in prediction accuracy when using model averaging with IT-AIC; our equivocal results suggest that more research is needed on its utility. We illustrate our arguments with worked examples from behavioural experiments.},
	language = {en},
	number = {1},
	urldate = {2020-03-11},
	journal = {Behavioral Ecology and Sociobiology},
	author = {Richards, Shane A. and Whittingham, Mark J. and Stephens, Philip A.},
	month = jan,
	year = {2011},
	pages = {77--89}
}


@article{karelus_effects_2017,
	title = {Effects of environmental factors and landscape features on movement patterns of {Florida} black bears},
	volume = {98},
	issn = {0022-2372},
	url = {https://academic.oup.com/jmammal/article/98/5/1463/3858329},
	doi = {10.1093/jmammal/gyx066},
	abstract = {Abstract.  A greater understanding of how environmental factors and anthropogenic landscape features influence animal movements can inform management and potent},
	language = {en},
	number = {5},
	urldate = {2020-03-11},
	journal = {Journal of Mammalogy},
	author = {Karelus, Dana L. and McCown, J. Walter and Scheick, Brian K. and van de Kerk, Madelon and Bolker, Benjamin M. and Oli, Madan K.},
	month = oct,
	year = {2017},
	note = {Publisher: Oxford Academic},
	pages = {1463--1478}
}


@article{jaeger_r2_2017,
	title = {An {R2} statistic for fixed effects in the generalized linear mixed model},
	volume = {44},
	issn = {0266-4763},
	url = {https://doi.org/10.1080/02664763.2016.1193725},
	doi = {10.1080/02664763.2016.1193725},
	abstract = {Measuring the proportion of variance explained (R2) by a statistical model and the relative importance of specific predictors (semi-partial R2) can be essential considerations when building a parsimonious statistical model. The R2 statistic is a familiar summary of goodness-of-fit for normal linear models and has been extended in various ways to more general models. In particular, the generalized linear mixed model (GLMM) extends the normal linear model and is used to analyze correlated (hierarchical), non-normal data structures. Although various R2 statistics have been proposed, there is no consensus in statistical literature for the most sensible definition of R2 in this context. This research aims to build upon existing knowledge and definitions of R2 and to concisely define the statistic for the GLMM. Here, we derive a model and semi-partial R2 statistic for fixed (population) effects in the GLMM by utilizing the penalized quasi-likelihood estimation method based on linearization. We show that our proposed R2 statistic generalizes the widely used marginal R2 statistic introduced by Nakagawa and Schielzeth, demonstrate our statistics capability in model selection, show the utility of semi-partial R2 statistics in longitudinal data analysis, and provide software that computes the proposed R2 statistic along with semi-partial R2 for individual fixed effects. The software provided is adapted for both SAS and R programming languages.},
	number = {6},
	urldate = {2020-03-11},
	journal = {Journal of Applied Statistics},
	author = {Jaeger, Byron C. and Edwards, Lloyd J. and Das, Kalyan and Sen, Pranab K.},
	month = apr,
	year = {2017},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/02664763.2016.1193725},
	keywords = {62-07, 62Fxx, 62Hxx, 62Pxx, Blood pressure, clustered data, generalized linear mixed model, R-squared, statistical software},
	pages = {1086--1105}
}

@Manual{r2glmm,
    title = {r2glmm: Computes R Squared for Mixed (Multilevel) Models},
    author = {Byron Jaeger},
    year = {2017},
    note = {R package version 0.1.2},
    url = {https://CRAN.R-project.org/package=r2glmm},
  }

@Article{dezeure_high_2015,
    title = {High-Dimensional Inference: Confidence Intervals, p-values and {R}-Software {hdi}},
    author = {Ruben Dezeure and Peter B\"uhlmann and Lukas Meier and Nicolai Meinshausen},
    journal = {Statistical Science},
    year = {2015},
    volume = {30},
    number = {4},
    pages = {533--558},
  }


@article{dushoff_i_2019,
	title = {I can see clearly now: {Reinterpreting} statistical significance},
	volume = {10},
	copyright = {© 2019 The Authors. Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society},
	issn = {2041-210X},
	shorttitle = {I can see clearly now},
	url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13159},
	doi = {10.1111/2041-210X.13159},
	abstract = {Null hypothesis significance testing (NHST) remains popular despite decades of concern about misuse and misinterpretation. There are many recent suggestions for mitigating problems arising from NHST, including calls for abandoning NHST in favour of Bayesian or information-theoretic approaches. We believe that NHST will continue to be widely used, and can be most usefully interpreted as a guide to whether a certain effect can be seen clearly in a particular context (e.g. whether we can clearly see that a correlation or between-group difference is positive or negative). We believe that much misinterpretation of NHST is due to language: significance testing has little to do with other meanings of the word ‘significance’. We therefore suggest that researchers describe the conclusions of null-hypothesis tests in terms of statistical ‘clarity’ rather than ‘significance’. We illustrate our point by rewriting common misinterpretations of the meaning of statistical tests found in the literature using the language of ‘clarity’. The meaning of statistical tests become easier to interpret and explain when viewed through the lens of ‘statistical clarity’. Our suggestion is mild, but practical: this simple semantic change could enhance clarity in statistical communication.},
	language = {en},
	number = {6},
	urldate = {2019-06-18},
	journal = {Methods in Ecology and Evolution},
	author = {Dushoff, Jonathan and Kain, Morgan P. and Bolker, Benjamin M.},
	year = {2019},
	keywords = {p-value, hypothesis testing, null hypothesis significance testing, statistical clarity, statistical philosophy, statistical significance},
	pages = {756--759}
}

@book{forsythe_computer_1977,
	address = {Englewood Cliffs, N.J},
	edition = {1st edition},
	title = {Computer {Methods} for {Mathematical} {Computations}},
	isbn = {978-0-13-165332-0},
	abstract = {Computer Methods for Mathematical Computations (Prentice-Hall series in automatic computation)},
	language = {English},
	publisher = {Prentice Hall},
	author = {Forsythe, George Elmer and Malcolm, Michael A. and Moler, Cleve B.},
	month = jan,
	year = {1977},
}

@article{pagel_bayesian_2006,
	title = {Bayesian {Analysis} of {Correlated} {Evolution} of {Discrete} {Characters} by {Reversible}‐{Jump} {Markov} {Chain} {Monte} {Carlo}},
	volume = {167},
	issn = {0003-0147, 1537-5323},
	url = {http://www.journals.uchicago.edu/doi/10.1086/503444},
	doi = {10.1086/503444},
	abstract = {We describe a Bayesian method for investigating correlated evolution of discrete binary traits on phylogenetic trees. The method ﬁts a continuous-time Markov model to a pair of traits, seeking the best ﬁtting models that describe their joint evolution on a phylogeny. We employ the methodology of reversible-jump (RJ) Markov chain Monte Carlo to search among the large number of possible models, some of which conform to independent evolution of the two traits, others to correlated evolution. The RJ Markov chain visits these models in proportion to their posterior probabilities, thereby directly estimating the support for the hypothesis of correlated evolution. In addition, the RJ Markov chain simultaneously estimates the posterior distributions of the rate parameters of the model of trait evolution. These posterior distributions can be used to test among alternative evolutionary scenarios to explain the observed data. All results are integrated over a sample of phylogenetic trees to account for phylogenetic uncertainty. We implement the method in a program called RJ Discrete and illustrate it by analyzing the question of whether mating system and advertisement of estrus by females have coevolved in the Old World monkeys and great apes.},
	language = {en},
	number = {6},
	urldate = {2021-05-06},
	journal = {The American Naturalist},
	author = {Pagel, Mark and Meade, Andrew},
	month = jun,
	year = {2006},
	pages = {808--825}
}


@article{roberts_cross-validation_2017,
	title = {Cross-validation strategies for data with temporal, spatial, hierarchical, or phylogenetic structure},
	volume = {40},
	issn = {09067590},
	url = {http://doi.wiley.com/10.1111/ecog.02881},
	doi = {10.1111/ecog.02881},
	language = {en},
	number = {8},
	urldate = {2017-09-13},
	journal = {Ecography},
	author = {Roberts, David R. and Bahn, Volker and Ciuti, Simone and Boyce, Mark S. and Elith, Jane and Guillera-Arroita, Gurutzeta and Hauenstein, Severin and Lahoz-Monfort, José J. and Schröder, Boris and Thuiller, Wilfried and Warton, David I. and Wintle, Brendan A. and Hartig, Florian and Dormann, Carsten F.},
	month = aug,
	year = {2017},
	pages = {913--929},
	file = {ecog2881.pdf:/home/bolker/Documents/zotero_new/storage/REZ7BUNJ/ecog2881.pdf:application/pdf},
}


@book{james_introduction_2013,
	title = {An introduction to statistical learning},
	volume = {112},
	publisher = {Springer},
	author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	year = {2013},
	file = {Full Text:/home/bolker/Documents/zotero_new/storage/KY22P8UZ/James et al. - 2013 - An introduction to statistical learning.pdf:application/pdf;Snapshot:/home/bolker/Documents/zotero_new/storage/AQBFJVSN/10.html:text/html},
}


@book{hastie_elements_2009,
	address = {New York},
	title = {The elements of statistical learning data mining, inference, and prediction},
	isbn = {978-0-387-84858-7 0-387-84858-4 978-0-387-84857-0 0-387-84857-6},
	url = {http://public.eblib.com/EBLPublic/PublicView.do?ptiID=437866},
	abstract = {"During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics."--Jacket.},
	language = {English},
	urldate = {2013-07-02},
	publisher = {Springer},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, J. H},
	year = {2009},
}




@article{li_fitting_2018,
	title = {Fitting mechanistic epidemic models to data: {A} comparison of simple {Markov} chain {Monte} {Carlo} approaches},
	volume = {27},
	doi = {10.1177/0962280217747054},
	abstract = {Simple mechanistic epidemic models are widely used for forecasting and parameter estimation of infectious diseases
based on noisy case reporting data. Despite the widespread application of models to emerging infectious diseases, we
know little about the comparative performance of standard computational-statistical frameworks in these contexts. Here
we build a simple stochastic, discrete-time, discrete-state epidemic model with both process and observation error and
use it to characterize the effectiveness of different flavours of Bayesian Markov chain Monte Carlo (MCMC) techniques.
We use fits to simulated data, where parameters (and future behaviour) are known, to explore the limitations of different
platforms and quantify parameter estimation accuracy, forecasting accuracy, and computational efficiency across
combinations of modeling decisions (e.g. discrete vs. continuous latent states, levels of stochasticity) and
computational platforms (JAGS, NIMBLE, Stan).},
	number = {7},
	journal = {Statistical Methods in Medical Research},
	author = {Li, Michael and Dushoff, Jonathan and Bolker, Benjamin M},
	year = {2018},
	pages = {1956--1967},
	file = {lunchbox_0962280217747054.pdf:/home/bolker/Documents/zotero_new/storage/R44Y57SS/lunchbox_0962280217747054.pdf:application/pdf},
}


@article{altman_bootstrap_1989,
	title = {Bootstrap investigation of the stability of a cox regression model},
	volume = {8},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4780080702},
	doi = {10.1002/sim.4780080702},
	abstract = {We describe a bootstrap investigation of the stability of a Cox proportional hazards regression model resulting from the analysis of a clinical trial of azathioprine versus placebo in patients with primary biliary cirrhosis. We have considered stability to refer both to the choice of variables included in the model and, more importantly, to the predictive ability of the model. In stepwise Cox regression analyses of 100 bootstrap samples using 17 candidate variables, the most frequently selected variables were those selected in the original analysis, and no other important variable was identified. Thus there was no reason to doubt the model obtained in the original analysis. For each patient in the trial, bootstrap confidence intervals were constructed for the estimated probability of surviving two years. It is shown graphically that these intervals are markedly wider than those obtained from the original model.},
	language = {en},
	number = {7},
	urldate = {2022-01-30},
	journal = {Statistics in Medicine},
	author = {Altman, Douglas G. and Andersen, Per Kragh},
	year = {1989},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.4780080702},
	keywords = {Bootstrap, Cox proportional hazards regression model, Model selection, Prediction, Primary biliary cirrhosis},
	pages = {771--783},
	file = {Full Text PDF:/home/bolker/Documents/zotero_new/storage/923QUKAH/Altman and Andersen - 1989 - Bootstrap investigation of the stability of a cox .pdf:application/pdf;Snapshot:/home/bolker/Documents/zotero_new/storage/ZBIKUL4K/sim.html:text/html},
}
                  

@misc{harrell_problems_1996,
	title = {Problems with stepwise regression},
	url = {https://www.stata.com/support/faqs/statistics/stepwise-regression-problems/},
	abstract = {What are some of the problems with stepwise regression?},
	urldate = {2022-01-30},
	journal = {Stata FAQ},
	author = {Harrell, Frank and Conroy, Ronan},
	year = {1996},
	file = {Snapshot:/home/bolker/Documents/zotero_new/storage/P55EFDLT/stepwise-regression-problems.html:text/html},
}


@article{dezeure_high-dimensional_2015,
	title = {High-{Dimensional} {Inference}: {Confidence} {Intervals}, p-{Values} and {R}-{Software} hdi},
	volume = {30},
	issn = {0883-4237},
	shorttitle = {High-{Dimensional} {Inference}},
	url = {http://www.jstor.org/stable/24780819},
	abstract = {We present a (selective) review of recent frequentist high-dimensional inference methods for constructing p-values and confidence intervals in linear and generalized linear models. We include a broad, comparative empirical study which complements the viewpoint from statistical methodology and theory. Furthermore, we introduce and illustrate the R-package hdi which easily allows the use of different methods and supports reproducibility.},
	number = {4},
	urldate = {2022-01-31},
	journal = {Statistical Science},
	author = {Dezeure, Ruben and Bühlmann, Peter and Meier, Lukas and Meinshausen, Nicolai},
	year = {2015},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {533--558},
	file = {JSTOR Full Text PDF:/home/bolker/Documents/zotero_new/storage/92X6S8LA/Dezeure et al. - 2015 - High-Dimensional Inference Confidence Intervals, .pdf:application/pdf},
}


@article{freedman_note_1983,
	title = {A {Note} on {Screening} {Regression} {Equations}},
	volume = {37},
	issn = {0003-1305},
	url = {https://www.tandfonline.com/doi/abs/10.1080/00031305.1983.10482729},
	doi = {10.1080/00031305.1983.10482729},
	abstract = {Consider developing a regression model in a context where substantive theory is weak. To focus on an extreme case, suppose that in fact there is no relationship between the dependent variable and the explanatory variables. Even so, if there are many explanatory variables, the R 2 will be high. If explanatory variables with small t statistics are dropped and the equation refitted, the R 2 will stay high and the overall F will become highly significant. This is demonstrated by simulation and by asymptotic calculation.},
	number = {2},
	urldate = {2022-01-31},
	journal = {The American Statistician},
	author = {Freedman, David A. and Freedman, David A.},
	month = may,
	year = {1983},
	note = {Publisher: Taylor \& Francis
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/00031305.1983.10482729},
	keywords = {F, Multiple testing, Regression},
	pages = {152--155},
	file = {Full Text PDF:/home/bolker/Documents/zotero_new/storage/F65B9AF4/Freedman and Freedman - 1983 - A Note on Screening Regression Equations.pdf:application/pdf;Snapshot:/home/bolker/Documents/zotero_new/storage/GKJBII8L/00031305.1983.html:text/html},
}


@article{cook_validation_2006,
	title = {Validation of {Software} for {Bayesian} {Models} {Using} {Posterior} {Quantiles}},
	volume = {15},
	issn = {1061-8600, 1537-2715},
	url = {http://www.tandfonline.com/doi/abs/10.1198/106186006X136976},
	doi = {10.1198/106186006X136976},
	language = {en},
	number = {3},
	urldate = {2021-05-19},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Cook, Samantha R and Gelman, Andrew and Rubin, Donald B},
	month = sep,
	year = {2006},
	pages = {675--692},
	file = {Cook et al. - 2006 - Validation of Software for Bayesian Models Using P.pdf:/home/bolker/Documents/zotero_new/storage/RRY6T73X/Cook et al. - 2006 - Validation of Software for Bayesian Models Using P.pdf:application/pdf},
}


@article{talts_validating_2020,
	title = {Validating {Bayesian} {Inference} {Algorithms} with {Simulation}-{Based} {Calibration}},
	url = {http://arxiv.org/abs/1804.06788},
	abstract = {Verifying the correctness of Bayesian computation is challenging. This is especially true for complex models that are common in practice, as these require sophisticated model implementations and algorithms. In this paper we introduce {\textbackslash}emph\{simulation-based calibration\} (SBC), a general procedure for validating inferences from Bayesian algorithms capable of generating posterior samples. This procedure not only identifies inaccurate computation and inconsistencies in model implementations but also provides graphical summaries that can indicate the nature of the problems that arise. We argue that SBC is a critical part of a robust Bayesian workflow, as well as being a useful tool for those developing computational algorithms and statistical software.},
	urldate = {2021-10-01},
	journal = {arXiv:1804.06788 [stat]},
	author = {Talts, Sean and Betancourt, Michael and Simpson, Daniel and Vehtari, Aki and Gelman, Andrew},
	month = oct,
	year = {2020},
	note = {arXiv: 1804.06788},
	keywords = {Statistics - Methodology},
	annote = {Comment: 19 pages, 13 figures},
	file = {arXiv Fulltext PDF:/home/bolker/Documents/zotero_new/storage/EKDL22K9/Talts et al. - 2020 - Validating Bayesian Inference Algorithms with Simu.pdf:application/pdf;arXiv.org Snapshot:/home/bolker/Documents/zotero_new/storage/UFWFFJ2P/1804.html:text/html},
}


@article{gelman_avoiding_1995,
	title = {Avoiding {Model} {Selection} in {Bayesian} {Social} {Research}},
	volume = {25},
	issn = {0081-1750},
	url = {http://www.jstor.org/stable/271064},
	doi = {10.2307/271064},
	urldate = {2018-05-15},
	journal = {Sociological Methodology},
	author = {Gelman, Andrew and Rubin, Donald B.},
	year = {1995},
	pages = {165--173},
}


@article{taper_evidential_2016,
	title = {Evidential statistics as a statistical modern synthesis to support 21st century science},
	volume = {58},
	issn = {1438-3896, 1438-390X},
	url = {http://link.springer.com/10.1007/s10144-015-0533-y},
	doi = {10.1007/s10144-015-0533-y},
	language = {en},
	number = {1},
	urldate = {2016-09-07},
	journal = {Population Ecology},
	author = {Taper, Mark L. and Ponciano, José Miguel},
	month = jan,
	year = {2016},
	pages = {9--29},
	file = {9_esaasmsts2cs.pdf:/home/bolker/Documents/zotero_new/storage/A95E45BP/9_esaasmsts2cs.pdf:application/pdf},
}


@article{crivelli_confidence_1995,
	title = {Confidence intervals in ridge regression by bootstrapping the dependent variable: a simulation study},
	volume = {24},
	issn = {0361-0918},
	shorttitle = {Confidence intervals in ridge regression by bootstrapping the dependent variable},
	url = {https://doi.org/10.1080/03610919508813264},
	doi = {10.1080/03610919508813264},
	abstract = {As it is well known, Ridge Regression can be a useful technique for estimating the coefficients of a Multiple Regression Model in the presence of multicollinearity. It has, however, the drawback that the distribution of the estimator is unknown, so that only asymptotic confidence intervals may be obtained. The aim of this paper is to report on the use of a technique that combines the Bootstrap and the Edgeworth Expansion to obtain an approximation to the distribution of some Ridge Regression estimators. Some simulation experiments were carried out to compare the asymptotic confidence intervals with those obtained with this technique},
	number = {3},
	urldate = {2022-01-29},
	journal = {Communications in Statistics - Simulation and Computation},
	author = {Crivelli, Ana and Firinguetti, Luis and Montaño, Rosa and Muñóz, Margarita},
	month = jan,
	year = {1995},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/03610919508813264},
	keywords = {bootstrap, collinearity, confidence intervals, Edgeworth expansion, ridge regression},
	pages = {631--652},
	file = {Full Text PDF:/home/bolker/Documents/zotero_new/storage/GKLZNTBS/Crivelli et al. - 1995 - Confidence intervals in ridge regression by bootst.pdf:application/pdf;Snapshot:/home/bolker/Documents/zotero_new/storage/RGJ7B5H7/03610919508813264.html:text/html},
}

@incollection{macneill_confidence_1987,
	address = {Dordrecht},
	title = {Confidence {Intervals} for {Ridge} {Regression} {Parameters}},
	isbn = {978-94-010-8624-0 978-94-009-4790-0},
	url = {http://link.springer.com/10.1007/978-94-009-4790-0_19},
	abstract = {This paper reviews various alternatives for constructing confidence in­ tervals for ridge regression (RR) parameters, and illustrates them with an example. Among the newer alternatives are bootstrapping and those based on Stein's (1981) unbiased estimate of the mean squared error (MSE) of a biased estimator of multivariate normal mean. A simulation study supports the validity of the confidence statements based on Stein's model as modified here for the ridge regression problem. It yields confidence intervals which can be more useful and reliable than those based on other methods.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {Time {Series} and {Econometric} {Modelling}},
	publisher = {Springer Netherlands},
	author = {Vinod, H. D.},
	editor = {MacNeill, Ian B. and Umphrey, Gary J. and Carter, Richard A. L. and McLeod, A. Ian and Ullah, Aman},
	year = {1987},
	doi = {10.1007/978-94-009-4790-0_19},
	pages = {279--300},
	file = {Vinod - 1987 - Confidence Intervals for Ridge Regression Paramete.pdf:/home/bolker/Documents/zotero_new/storage/ARRZ28QL/Vinod - 1987 - Confidence Intervals for Ridge Regression Paramete.pdf:application/pdf},
}


@article{efron_automatic_2020,
	title = {The {Automatic} {Construction} of {Bootstrap} {Confidence} {Intervals}},
	volume = {29},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2020.1714633},
	doi = {10.1080/10618600.2020.1714633},
	abstract = {The standard intervals, for example, θ̂±1.96σ̂ for nominal 95\% two-sided coverage, are familiar and easy to use, but can be of dubious accuracy in regular practice. Bootstrap confidence intervals offer an order of magnitude improvement—from first order to second order accuracy. This article introduces a new set of algorithms that automate the construction of bootstrap intervals, substituting computer power for the need to individually program particular applications. The algorithms are described in terms of the underlying theory that motivates them, along with examples of their application. They are implemented in the R package bcaboot. Supplementary materials for this article are available online.},
	number = {3},
	urldate = {2022-01-31},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Efron, Bradley and Narasimhan, Balasubramanian},
	month = jul,
	year = {2020},
	pmid = {33727780},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10618600.2020.1714633},
	keywords = {bca method, Exponential families, Nonparametric intervals, Second-order accuracy},
	pages = {608--619},
	file = {Full Text PDF:/home/bolker/Documents/zotero_new/storage/LNH5Q2C2/Efron and Narasimhan - 2020 - The Automatic Construction of Bootstrap Confidence.pdf:application/pdf},
}



@article{buhlmann_high-dimensional_2014,
	title = {High-dimensional variable screening and bias in subsequent inference, with an empirical comparison},
	volume = {29},
	issn = {1613-9658},
	url = {https://doi.org/10.1007/s00180-013-0436-3},
	doi = {10.1007/s00180-013-0436-3},
	abstract = {We review variable selection and variable screening in high-dimensional linear models. Thereby, a major focus is an empirical comparison of various estimation methods with respect to true and false positive selection rates based on 128 different sparse scenarios from semi-real data (real data covariables but synthetic regression coefficients and noise). Furthermore, we present some theoretical bounds for the bias in subsequent least squares estimation, using the selected variables from the first stage, which have direct implications for construction of p-values for regression coefficients.},
	language = {en},
	number = {3},
	urldate = {2022-06-06},
	journal = {Computational Statistics},
	author = {Bühlmann, Peter and Mandozzi, Jacopo},
	month = jun,
	year = {2014},
	keywords = {Elastic net, Lasso, Linear model, Ridge, Sparsity, Sure independence screening, Variable selection},
	pages = {407--430},
	file = {Full Text PDF:/home/bolker/Documents/zotero_new/storage/GE5ABT2K/Bühlmann and Mandozzi - 2014 - High-dimensional variable screening and bias in su.pdf:application/pdf},
}


@incollection{belloni_inference_2013,
	address = {Cambridge},
	title = {Inference for {High}-{Dimensional} {Sparse} {Econometric} {Models}},
	isbn = {978-1-139-06003-5},
	url = {https://www.cambridge.org/core/product/identifier/CBO9781139060035A018/type/book_part},
	abstract = {This article is about estimation and inference methods for high dimensional sparse (HDS) regression models in econometrics. High dimensional sparse models arise in situations where many regressors (or series terms) are available and the regression function is wellapproximated by a parsimonious, yet unknown set of regressors. The latter condition makes it possible to estimate the entire regression function eﬀectively by searching for approximately the right set of regressors. We discuss methods for identifying this set of regressors and estimating their coeﬃcients based on ℓ1-penalization and describe key theoretical results. In order to capture realistic practical situations, we expressly allow for imperfect selection of regressors and study the impact of this imperfect selection on estimation and inference results. We focus the main part of the article on the use of HDS models and methods in the instrumental variables model and the partially linear model. We present a set of novel inference results for these models and illustrate their use with applications to returns to schooling and growth regression.},
	language = {en},
	urldate = {2022-06-06},
	booktitle = {Advances in {Economics} and {Econometrics}},
	publisher = {Cambridge University Press},
	author = {Belloni, Alexandre and Chernozhukov, Victor and Hansen, Christian B.},
	editor = {Acemoglu, Daron and Arellano, Manuel and Dekel, Eddie},
	year = {2013},
	doi = {10.1017/CBO9781139060035.008},
	pages = {245--295},
	file = {Belloni et al. - 2013 - Inference for High-Dimensional Sparse Econometric .pdf:/home/bolker/Documents/zotero_new/storage/PUG9YBIK/Belloni et al. - 2013 - Inference for High-Dimensional Sparse Econometric .pdf:application/pdf},
}


@article{pearl_interpretation_2019,
	title = {On the {Interpretation} of do(x)},
	volume = {7},
	issn = {2193-3685},
	url = {https://www.degruyter.com/document/doi/10.1515/jci-2019-2002/html?lang=en},
	doi = {10.1515/jci-2019-2002},
	abstract = {This paper provides empirical interpretation of the do(x)do(x) operator when applied to non-manipulable variables such as race, obesity, or cholesterol level. We view do(x)do(x) as an ideal intervention that provides valuable information on the effects of manipulable variables and is thus empirically testable. We draw parallels between this interpretation and ways of enabling machines to learn effects of untried actions from those tried. We end with the conclusion that researchers need not distinguish manipulable from non-manipulable variables; both types are equally eligible to receive the do(x)do(x) operator and to produce useful information for decision makers.},
	language = {en},
	number = {1},
	urldate = {2022-06-06},
	journal = {Journal of Causal Inference},
	author = {Pearl, Judea},
	month = mar,
	year = {2019},
	note = {Publisher: De Gruyter},
	keywords = {causal effects, interventions, Manipulability, reinforcement learning, testability},
	file = {Full Text PDF:/home/bolker/Documents/zotero_new/storage/F2277G86/Pearl - 2019 - On the Interpretation of do(x).pdf:application/pdf},
}



@article{potscher_confidence_2009,
	title = {Confidence {Sets} {Based} on {Sparse} {Estimators} {Are} {Necessarily} {Large}},
	volume = {71},
	issn = {0976-836X},
	url = {https://www.jstor.org/stable/41337314},
	abstract = {Confidence sets based on sparse estimators are shown to be large compared to more standard confidence sets, demonstrating that sparsity of an estimator comes at a substantial price in terms of the quality of the estimator. The results are set in a general parametric or semiparametric framework.},
	number = {1},
	urldate = {2022-06-06},
	journal = {Sankhyā: The Indian Journal of Statistics, Series A (2008-)},
	author = {Pötscher, Benedikt M.},
	year = {2009},
	note = {Publisher: [Springer, Indian Statistical Institute]},
	pages = {1--18},
	file = {JSTOR Full Text PDF:/home/bolker/Documents/zotero_new/storage/P6VRQEYU/Pötscher - 2009 - Confidence Sets Based on Sparse Estimators Are Nec.pdf:application/pdf},
}

@Article{chernozhukov_hdm_2016,
    title = {{hdm}: High-Dimensional Metrics},
    author = {Victor Chernozhukov and Chris Hansen and Martin Spindler},
    journal = {R Journal},
    year = {2016},
    volume = {8},
    number = {2},
    pages = {185-199},
    url = {https://journal.r-project.org/archive/2016/RJ-2016-040/index.html},
  }

@article{chandrashekarSurvey2014,
  title = {A Survey on Feature Selection Methods},
  author = {Chandrashekar, Girish and Sahin, Ferat},
  year = {2014},
  month = jan,
  journal = {Computers \& Electrical Engineering},
  volume = {40},
  number = {1},
  pages = {16--28},
  issn = {0045-7906},
  doi = {10.1016/j.compeleceng.2013.11.024},
  urldate = {2023-07-18},
  abstract = {Plenty of feature selection methods are available in literature due to the availability of data with hundreds of variables leading to data with very high dimension. Feature selection methods provides us a way of reducing computation time, improving prediction performance, and a better understanding of the data in machine learning or pattern recognition applications. In this paper we provide an overview of some of the methods present in literature. The objective is to provide a generic introduction to variable elimination which can be applied to a wide array of machine learning problems. We focus on Filter, Wrapper and Embedded methods. We also apply some of the feature selection techniques on standard datasets to demonstrate the applicability of feature selection techniques.},
  langid = {english},
  file = {/home/bolker/Zotero/storage/SPLHSFQK/S0045790613003066.html}
}

@book{bernardoBayesian1994,
  title = {Bayesian {{Theory}}},
  author = {Bernardo, Jos{\'e} M. and Smith, Adrian F. M.},
  year = {1994},
  edition = {1},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/9780470316870},
  urldate = {2023-07-18},
  file = {/home/bolker/Zotero/storage/2WU5VN2Y/9780470316870.html}
}

@article{taylorPostselection2018,
  title = {Post-Selection Inference for {{L1-penalized}} Likelihood Models},
  author = {Taylor, Jonathan and Tibshirani, Robert},
  year = {2018},
  journal = {Canadian Journal of Statistics},
  volume = {46},
  number = {1},
  pages = {41--61},
  issn = {1708-945X},
  doi = {10.1002/cjs.11313},
  urldate = {2023-07-18},
  abstract = {We present a new method for post-selection inference for (lasso)'penalized likelihood models, including generalized regression models. Our approach generalizes the post-selection framework presented in Lee et al. (2013). The method provides P-values and confidence intervals that are asymptotically valid, conditional on the inherent selection done by the lasso. We present applications of this work to (regularized) logistic regression, Cox's proportional hazards model, and the graphical lasso. We do not provide rigorous proofs here of the claimed results, but rather conceptual and theoretical sketches. The Canadian Journal of Statistics 46: 41\textendash 61; 2018 \textcopyright{} 2017 Statistical Society of Canada},
  copyright = {\textcopyright{} 2017 Statistical Society of Canada},
  langid = {english},
  keywords = {Cox model,Logistic regression,MSC2010: Primary 97K70,P-values,Secondary 97K80}
}

@article{robertsCrossvalidation2016,
  title = {Cross-Validation Strategies for Data with Temporal, Spatial, Hierarchical, or Phylogenetic Structure},
  author = {Roberts, David R. and Bahn, Volker and Ciuti, Simone and Boyce, Mark S. and Elith, Jane and {Guillera-Arroita}, Gurutzeta and Hauenstein, Severin and {Lahoz-Monfort}, Jos{\'e} J. and Schr{\"o}der, Boris and Thuiller, Wilfried and Warton, David I. and Wintle, Brendan A. and Hartig, Florian and Dormann, Carsten F.},
  year = {2016},
  month = dec,
  journal = {Ecography},
  pages = {913-929},
  issn = {1600-0587},
  doi = {10.1111/ecog.02881},
  urldate = {2017-01-13},
  abstract = {Ecological data often show temporal, spatial, hierarchical (random effects), or phylogenetic structure. Modern statistical approaches are increasingly accounting for such dependencies. However, when performing cross-validation, these structures are regularly ignored, resulting in serious underestimation of predictive error. One cause for the poor performance of uncorrected (random) cross-validation, noted often by modellers, are dependence structures in the data that persist as dependence structures in model residuals, violating the assumption of independence. Even more concerning, because often overlooked, is that structured data also provides ample opportunity for overfitting with non-causal predictors. This problem can persist even if remedies such as autoregressive models, generalized least squares, or mixed models are used. Block cross-validation, where data are split strategically rather than randomly, can address these issues. However, the blocking strategy must be carefully considered. Blocking in space, time, random effects or phylogenetic distance, while accounting for dependencies in the data, may also unwittingly induce extrapolations by restricting the ranges or combinations of predictor variables available for model training, thus overestimating interpolation errors. On the other hand, deliberate blocking in predictor space may also improve error estimates when extrapolation is the modelling goal. Here, we review the ecological literature on non-random and blocked cross-validation approaches. We also provide a series of simulations and case studies, in which we show that, for all instances tested, block cross-validation is nearly universally more appropriate than random cross-validation if the goal is predicting to new data or predictor space, or for selecting causal predictors. We recommend that block cross-validation be used wherever dependence structures exist in a dataset, even if no correlation structure is visible in the fitted model residuals, or if the fitted models account for such correlations. This article is protected by copyright. All rights reserved.},
  langid = {english},
  keywords = {Autocorrelation,evaluation,extrapolation,independence,resource selection functions,species distribution models},
  file = {/home/bolker/Zotero/storage/92R6M8UD/abstract.html}
}

@article{arifPredictive2022a,
  title = {Predictive Models Aren't for Causal Inference},
  author = {Arif, Suchinta and MacNeil, M. Aaron},
  year = {2022},
  journal = {Ecology Letters},
  volume = {25},
  number = {8},
  pages = {1741--1745},
  issn = {1461-0248},
  doi = {10.1111/ele.14033},
  urldate = {2023-07-22},
  abstract = {Ecologists often rely on observational data to understand causal relationships. Although observational causal inference methodologies exist, predictive techniques such as model selection based on information criterion (e.g. AIC) remains a common approach used to understand ecological relationships. However, predictive approaches are not appropriate for drawing causal conclusions. Here, we highlight the distinction between predictive and causal inference and show how predictive techniques can lead to biased causal estimates. Instead, we encourage ecologists to valid causal inference methods such as the backdoor criterion, a graphical rule that can be used to determine causal relationships across observational studies.},
  copyright = {\textcopyright{} 2022 John Wiley \& Sons Ltd.},
  langid = {english},
  keywords = {back-door criterion,causal inference,directed acyclic graphs (DAGs),model selection,prediction},
  file = {/home/bolker/Zotero/storage/DPVUJZ76/Arif and MacNeil - 2022 - Predictive models aren't for causal inference.pdf}
}

@article{kimmelCausal2021,
  title = {Causal Assumptions and Causal Inference in Ecological Experiments},
  author = {Kimmel, Kaitlin and Dee, Laura E. and Avolio, Meghan L. and Ferraro, Paul J.},
  year = {2021},
  month = dec,
  journal = {Trends in Ecology \& Evolution},
  volume = {36},
  number = {12},
  pages = {1141--1152},
  publisher = {{Elsevier}},
  issn = {0169-5347},
  doi = {10.1016/j.tree.2021.08.008},
  urldate = {2023-07-22},
  langid = {english},
  pmid = {34538502},
  keywords = {counterfactual causality,excludability,exclusion restriction,interference,noncompliance,potential outcomes}
}

@article{laubachBiologist2021,
  title = {A Biologist's Guide to Model Selection and Causal Inference},
  author = {Laubach, Zachary M. and Murray, Eleanor J. and Hoke, Kim L. and Safran, Rebecca J. and Perng, Wei},
  year = {2021},
  month = jan,
  journal = {Proceedings of the Royal Society B: Biological Sciences},
  volume = {288},
  number = {1943},
  pages = {20202815},
  publisher = {{Royal Society}},
  doi = {10.1098/rspb.2020.2815},
  urldate = {2023-07-22},
  abstract = {A goal of many research programmes in biology is to extract meaningful insights from large, complex datasets. Researchers in ecology, evolution and behavior (EEB) often grapple with long-term, observational datasets from which they construct models to test causal hypotheses about biological processes. Similarly, epidemiologists analyse large, complex observational datasets to understand the distribution and determinants of human health. A key difference in the analytical workflows for these two distinct areas of biology is the delineation of data analysis tasks and explicit use of causal directed acyclic graphs (DAGs), widely adopted by epidemiologists. Here, we review the most recent causal inference literature and describe an analytical workflow that has direct applications for EEB. We start this commentary by defining four distinct analytical tasks (description, prediction, association, causal inference). The remainder of the text is dedicated to causal inference, specifically focusing on the use of DAGs to inform the modelling strategy. Given the increasing interest in causal inference and misperceptions regarding this task, we seek to facilitate an exchange of ideas between disciplinary silos and provide an analytical framework that is particularly relevant for making causal inference from observational data.},
  keywords = {association,causal inference,description,directed acyclic graphs,epidemiology,prediction},
  file = {/home/bolker/Zotero/storage/7LIZ9QXM/Laubach et al. - 2021 - A biologist's guide to model selection and causal .pdf}
}


@article{wangInterval2013b,
  title = {Interval Estimation by Frequentist Model Averaging},
  author = {Wang, Haiying and Zhou, Sherry Z. F.},
  year = {2013},
  month = dec,
  journal = {Communications in Statistics - Theory and Methods},
  volume = {42},
  number = {23},
  pages = {4342--4356},
  publisher = {{Taylor \& Francis}},
  issn = {0361-0926},
  doi = {10.1080/03610926.2011.647218},
  urldate = {2023-07-22},
  abstract = {An important contribution to the literature on frequentist model averaging (FMA) is the work of Hjort and Claeskens (2003), who developed an asymptotic theory for frequentist model averaging in parametric models based on a local mis-specification framework. They also proposed a simple method for constructing confidence intervals of the unknown parameters. This article shows that the confidence intervals based on the FMA estimator suggested by Hjort and Claeskens (2003) are asymptotically equivalent to that obtained from the full model under both parametric and the varying-coefficient partially linear models. Thus, as long as interval estimation rather than point estimation is concerned, the confidence interval based on the full model already fulfills the objective and model averaging provides no additional useful information.},
  keywords = {Asymptotic equivalence,Confidence interval,Model averaging,Parametric model,Primary 62E20,Secondary 62F12,Semi-parametric model},
  file = {/home/bolker/Zotero/storage/FW9E9IFF/Wang and Zhou - 2013 - Interval Estimation by Frequentist Model Averaging.pdf}
}

@article{hjortFrequentist2003,
  title = {Frequentist {{Model Average Estimators}}},
  author = {Hjort, Nils Lid and Claeskens, Gerda},
  year = {2003},
  month = dec,
  journal = {Journal of the American Statistical Association},
  volume = {98},
  number = {464},
  pages = {879--899},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1198/016214503000000828},
  urldate = {2023-07-22},
  abstract = {The traditional use of model selection methods in practice is to proceed as if the final selected model had been chosen in advance, without acknowledging the additional uncertainty introduced by model selection. This often means underreporting of variability and too optimistic confidence intervals. We build a general large-sample likelihood apparatus in which limiting distributions and risk properties of estimators post-selection as well as of model average estimators are precisely described, also explicitly taking modeling bias into account. This allows a drastic reduction in complexity, as competing model averaging schemes may be developed, discussed, and compared inside a statistical prototype experiment where only a few crucial quantities matter. In particular, we offer a frequentist view on Bayesian model averaging methods and give a link to generalized ridge estimators. Our work also leads to new model selection criteria. The methods are illustrated with real data applications.},
  keywords = {Bias and variance balance,Growing models,Likelihood inference,Model average estimators,Model information criteria,Moderate misspecification},
  file = {/home/bolker/Zotero/storage/DIXZ775S/Hjort and Claeskens - 2003 - Frequentist Model Average Estimators.pdf}
}



@article{mengStatistical2018,
	title = {Statistical paradises and paradoxes in big data ({I}): {Law} of large populations, big data paradox, and the 2016 {US} presidential election},
	volume = {12},
	issn = {1932-6157, 1941-7330},
	shorttitle = {Statistical paradises and paradoxes in big data ({I})},
	url = {https://projecteuclid.org/euclid.aoas/1532743473},
	doi = {10.1214/18-AOAS1161SF},
	abstract = {Statisticians are increasingly posed with thought-provoking and even paradoxical questions, challenging our qualifications for entering the statistical paradises created by Big Data. By developing measures for data quality, this article suggests a framework to address such a question: “Which one should I trust more: a 1\% survey with 60\% response rate or a self-reported administrative dataset covering 80\% of the population?” A 5-element Euler-formula-like identity shows that for any dataset of size nnn, probabilistic or not, the difference between the sample average X¯¯¯¯nX¯n{\textbackslash}overline\{X\}\_\{n\} and the population average X¯¯¯¯NX¯N{\textbackslash}overline\{X\}\_\{N\} is the product of three terms: (1) a data quality measure, ρR,XρR,X{\textbackslash}rho\_\{\{R,X\}\}, the correlation between XjXjX\_\{j\} and the response/recording indicator RjRjR\_\{j\}; (2) a data quantity measure, (N−n)/n−−−−−−−−−√(N−n)/n{\textbackslash}sqrt\{(N-n)/n\}, where NNN is the population size; and (3) a problem difficulty measure, σXσX{\textbackslash}sigma\_\{X\}, the standard deviation of XXX. This decomposition provides multiple insights: (I) Probabilistic sampling ensures high data quality by controlling ρR,XρR,X{\textbackslash}rho\_\{\{R,X\}\} at the level of N−1/2N−1/2N{\textasciicircum}\{-1/2\}; (II) When we lose this control, the impact of NNN is no longer canceled by ρR,XρR,X{\textbackslash}rho\_\{\{R,X\}\}, leading to a Law of Large Populations (LLP), that is, our estimation error, relative to the benchmarking rate 1/n−−√1/n1/{\textbackslash}sqrt\{n\}, increases with N−−√N{\textbackslash}sqrt\{N\}; and (III) the “bigness” of such Big Data (for population inferences) should be measured by the relative size f=n/Nf=n/Nf=n/N, not the absolute size nnn; (IV) When combining data sources for population inferences, those relatively tiny but higher quality ones should be given far more weights than suggested by their sizes. Estimates obtained from the Cooperative Congressional Election Study (CCES) of the 2016 US presidential election suggest a ρR,X≈−0.005ρR,X≈−0.005{\textbackslash}rho\_\{\{R,X\}\}{\textbackslash}approx-0.005 for self-reporting to vote for Donald Trump. Because of LLP, this seemingly minuscule data defect correlation implies that the simple sample proportion of the self-reported voting preference for Trump from 1\%1\%1{\textbackslash}\% of the US eligible voters, that is, n≈2,300,000n≈2,300,000n{\textbackslash}approx2{\textbackslash}mbox\{,\}300{\textbackslash}mbox\{,\}000, has the same mean squared error as the corresponding sample proportion from a genuine simple random sample of size n≈400n≈400n{\textbackslash}approx400, a 99.98\%99.98\%99.98{\textbackslash}\% reduction of sample size (and hence our confidence). The CCES data demonstrate LLP vividly: on average, the larger the state’s voter populations, the further away the actual Trump vote shares from the usual 95\%95\%95{\textbackslash}\% confidence intervals based on the sample proportions. This should remind us that, without taking data quality into account, population inferences with Big Data are subject to a Big Data Paradox: the more the data, the surer we fool ourselves.},
	language = {EN},
	number = {2},
	urldate = {2020-08-01},
	journal = {Annals of Applied Statistics},
	author = {Meng, Xiao-Li},
	month = jun,
	year = {2018},
	mrnumber = {MR3834282},
	zmnumber = {06980472},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Bias-variance tradeoff, data confidentiality and privacy, data defect correlation, data defect index (d.d.i.), data quality-quantity tradeoff, Euler identity, Monte Carlo and Quasi Monte Carlo (MCQMC), non-response bias},
	pages = {685--726},
	file = {Snapshot:/home/bolker/Documents/zotero_new/storage/NGH7IJCE/1532743473.html:text/html;Submitted Version:/home/bolker/Documents/zotero_new/storage/MNETFS2E/Meng - 2018 - Statistical paradises and paradoxes in big data (I.pdf:application/pdf},
}

@article{burnhamMultimodel2004b,
	title = {Multimodel Inference: Understanding {AIC} and {BIC} in Model Selection},
	volume = {33},
	issn = {1552-8294},
	shorttitle = {Multimodel {Inference}},
	doi = {10.1177/0049124104268644},
	abstract = {The model selection literature has been generally poor at reflecting the deep foundations of the Akaike information criterion (AIC) and at making appropriate comparisons to the Bayesian information criterion (BIC). There is a clear philosophy, a sound criterion based in information theory, and a rigorous statistical foundation for AIC. AIC can be justified as Bayesian using a "savvy" prior on models that is a function of sample size and the number of model parameters. Furthermore, BIC can be derived as a non-Bayesian result. Therefore, arguments about using AIC versus BIC for model selection cannot be from a Bayes versus frequentist perspective. The philosophical context of what is assumed about reality, approximating models, and the intent of model-based inference should determine whether AIC or BIC is used. Various facets of such multimodel inference are presented here, particularly methods of model averaging. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Sociological Methods \& Research},
	author = {Burnham, Kenneth P. and Anderson, David R.},
	year = {2004},
	note = {Place: US
Publisher: Sage Publications},
	keywords = {Information Theory, Mathematical Modeling, Statistical Analysis, Statistical Probability, Stochastic Modeling},
	pages = {261--304},
}

@article{johnsonModel2004a,
  title = {Model Selection in Ecology and Evolution},
  author = {Johnson, Jerald B. and Omland, Kristian S.},
  year = {2004},
  month = feb,
  journal = {Trends in Ecology \& Evolution},
  volume = {19},
  number = {2},
  pages = {101--108},
  publisher = {{Elsevier}},
  issn = {0169-5347},
  doi = {10.1016/j.tree.2003.10.013},
  urldate = {2024-02-29},
  langid = {english},
  pmid = {16701236},
  file = {/home/bolker/Zotero/storage/8ZSEGC5M/Johnson and Omland - 2004 - Model selection in ecology and evolution.pdf}
}

@article{lemoineMoving2019a,
  title = {Moving beyond Noninformative Priors: Why and How to Choose Weakly Informative Priors in {{Bayesian}} Analyses},
  shorttitle = {Moving beyond Noninformative Priors},
  author = {Lemoine, Nathan P.},
  year = {2019},
  journal = {Oikos},
  volume = {128},
  number = {7},
  pages = {912--928},
  issn = {1600-0706},
  doi = {10.1111/oik.05985},
  urldate = {2020-05-26},
  abstract = {Throughout the last two decades, Bayesian statistical methods have proliferated throughout ecology and evolution. Numerous previous references established both philosophical and computational guidelines for implementing Bayesian methods. However, protocols for incorporating prior information, the defining characteristic of Bayesian philosophy, are nearly nonexistent in the ecological literature. Here, I hope to encourage the use of weakly informative priors in ecology and evolution by providing a `consumer's guide' to weakly informative priors. The first section outlines three reasons why ecologists should abandon noninformative priors: 1) common flat priors are not always noninformative, 2) noninformative priors provide the same result as simpler frequentist methods, and 3) noninformative priors suffer from the same high type I and type M error rates as frequentist methods. The second section provides a guide for implementing informative priors, wherein I detail convenient `reference' prior distributions for common statistical models (i.e. regression, ANOVA, hierarchical models). I then use simulations to visually demonstrate how informative priors influence posterior parameter estimates. With the guidelines provided here, I hope to encourage the use of weakly informative priors for Bayesian analyses in ecology. Ecologists can and should debate the appropriate form of prior information, but should consider weakly informative priors as the new `default' prior for any Bayesian model.},
  copyright = {{\copyright} 2019 The Authors},
  langid = {english},
  keywords = {Bayesian statistics,frequentist statistics,Markov chain Monte Carlo,vague priors},
  file = {/home/bolker/Zotero/storage/9E65FFUC/Lemoine - 2019 - Moving beyond noninformative priors why and how t.pdf;/home/bolker/Zotero/storage/HLI5JXEM/oik.html}
}
