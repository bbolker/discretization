
@misc{fox_why_2016,
	title = {Why don’t more ecologists use strong inference?},
	url = {https://dynamicecology.wordpress.com/2016/06/01/obstacles-to-strong-inference-in-ecology/},
	abstract = {Platt (1964 Science) is a classic practical statement of philosophy of science by a scientist. Briefly, Platt argues that some fields of science progress faster than others, and that this is neithe…},
	urldate = {2016-07-02},
	journal = {Dynamic Ecology},
	author = {Fox, Jeremy},
	year = {2016},
	file = {Snapshot:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/KNSK83UK/comment-page-1.html:text/html}
}

@misc{mcgill_why_2016,
	title = {Why ecology is hard (and fun) – multicausality},
	url = {https://dynamicecology.wordpress.com/2016/03/02/why-ecology-is-hard-and-fun-multicausality/},
	abstract = {Mark recently wrote a piece musing on the true fact that many ecologists have evolution envy   – wishing to find simply general rules in ecology that match the elegance of evolution, which wa…},
	urldate = {2016-07-02},
	journal = {Dynamic Ecology},
	author = {McGill, Brian},
	year = {2016},
	file = {Snapshot:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/CDSVG8MC/why-ecology-is-hard-and-fun-multicausality.html:text/html}
}


@article{platt_strong_1964,
	series = {New {Series}},
	title = {Strong {Inference}},
	volume = {146},
	issn = {00368075},
	url = {http://www.jstor.org/stable/1714268},
	doi = {10.2307/1714268},
	number = {3642},
	urldate = {2009-04-14},
	journal = {Science},
	author = {Platt, John R.},
	year = {1964},
	note = {ArticleType: primary\_article / Full publication date: Oct. 16, 1964 / Copyright © 1964 American Association for the Advancement of Science},
	pages = {347--353}
}


@article{barker_truth_2015,
	title = {Truth, models, model sets, {AIC}, and multimodel inference: {A} {Bayesian} perspective},
	volume = {79},
	copyright = {Published 2015. This article is a U.S. Government work and is in the public domain in the USA.},
	issn = {1937-2817},
	shorttitle = {Truth, models, model sets, {AIC}, and multimodel inference},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/jwmg.890/abstract},
	doi = {10.1002/jwmg.890},
	abstract = {Statistical inference begins with viewing data as realizations of stochastic processes. Mathematical models provide partial descriptions of these processes; inference is the process of using the data to obtain a more complete description of the stochastic processes. Wildlife and ecological scientists have become increasingly concerned with the conditional nature of model-based inference: what if the model is wrong? Over the last 2 decades, Akaike's Information Criterion (AIC) has been widely and increasingly used in wildlife statistics for 2 related purposes, first for model choice and second to quantify model uncertainty. We argue that for the second of these purposes, the Bayesian paradigm provides the natural framework for describing uncertainty associated with model choice and provides the most easily communicated basis for model weighting. Moreover, Bayesian arguments provide the sole justification for interpreting model weights (including AIC weights) as coherent (mathematically self consistent) model probabilities. This interpretation requires treating the model as an exact description of the data-generating mechanism. We discuss the implications of this assumption, and conclude that more emphasis is needed on model checking to provide confidence in the quality of inference. Published 2015. This article is a U.S. Government work and is in the public domain in the USA.},
	language = {en},
	number = {5},
	urldate = {2015-07-10},
	journal = {The Journal of Wildlife Management},
	author = {Barker, Richard J. and Link, William A.},
	year = {2015},
	keywords = {AIC, Bayesian analysis, BIC, DIC, model selection, multi-model inference},
	pages = {730--738}
}


@article{luttbeg_comparing_2004,
	title = {Comparing {Alternative} {Models} to {Empirical} {Data}: {Cognitive} {Models} of {Western} {Scrub}-{Jay} {Foraging} {Behavior}},
	volume = {163},
	issn = {0003-0147},
	shorttitle = {Comparing {Alternative} {Models} to {Empirical} {Data}},
	url = {http://www.jstor.org/stable/10.1086/381319},
	doi = {10.1086/381319},
	abstract = {Abstract: Animals often select one item from a set of candidates, as when choosing a foraging site or mate, and are expected to possess accurate and efficient rules for acquiring information and making decisions. Little is known, however, about the decision rules animals use. We compare patterns of information sampling by western scrub-jays (Aphelocoma californica) when choosing a nut with three decision rules: best of n (BN), flexible threshold (FT), and comparative Bayes (CB). First, we use a null hypothesis testing approach and find that the CB decision rule, in which individuals use past experiences to make nonrandom assessment and choice decisions, produces patterns of behavior that more closely correspond to observed patterns of nut sampling in scrub-jays than the other two rules. This approach does not allow us to quantify how much better CB is at predicting scrub-jay behavior than the other decision rules. Second, we use a model selection approach that uses Akaike Information Criteria to quantify how well alternative models approximate observed data. We find that the CB rule is much more likely to produce the observed patterns of scrub-jay behavior than the other rules. This result provides some of the best empirical evidence of the use of Bayesian information updating by a nonhuman animal.},
	number = {2},
	urldate = {2016-07-02},
	journal = {The American Naturalist},
	author = {Luttbeg, Barney and Langen, Tom A. and Adams, Associate Editor: Eldridge S.},
	year = {2004},
	pages = {263--276}
}


@article{cade_model_2015,
	title = {Model averaging and muddled multimodel inference},
	issn = {0012-9658},
	url = {http://www.esajournals.org/doi/abs/10.1890/14-1639.1},
	doi = {10.1890/14-1639.1},
	abstract = {Three flawed practices associated with model averaging coefficients for predictor variables in regression models commonly occur when making multimodel inferences in analyses of ecological data.  Model-averaged regression coefficients based on Akaike Information Criterion (AIC) weights were recommended by Burnham and Anderson (2002, 2004) for addressing model uncertainty but they are not valid, interpretable estimates of partial effects for individual predictors when there is multicollinearity among the predictor variables.  Multicollinearity implies that the scaling of units in the denominators of the regression coefficients may change across models such that neither the parameters nor their estimates have common scales, and thus averaging them makes no sense.  The associated sums of AIC model weights recommended to assess relative importance of individual predictors are a measure of relative importance of models, with little information about contributions by individual predictors.  Sometimes the model-averaged regression coefficients for predictor variables are incorrectly used to make model-averaged predictions of the response variable when the models are not linear in the parameters.  I demonstrate the issues with the first two practices using the college grade point average example extensively analyzed by Burnham and Anderson (2002).  I show how partial standard deviations of the predictor variables can be used to detect changing scales of their estimates with multicollinearity.  Standardizing estimates based on partial standard deviations for their variables can be used to make the scaling of the estimates commensurate across models, a necessary but not sufficient condition for model averaging of the estimates to be sensible.  The standardized estimates or equivalently the t-statistics on unstandardized estimates also can be used to provide more informative measures of relative importance than sums of AIC weights.  Finally, I illustrate how seriously compromised statistical interpretations and predictions can be for all three of these flawed practices by critiquing their use in a recent species distribution modeling technique developed by Rice et al. (2013) for predicting greater sage-grouse (Centrocercus urophasianus) distribution in Colorado.  These model averaging issues are common in other ecological literature and ought to be discontinued if we are to make effective scientific contributions to ecological knowledge and conservation of natural resources.},
	urldate = {2015-03-22},
	journal = {Ecology},
	author = {Cade, Brian S.},
	year = {2015}
}


@article{grueber_multimodel_2011,
	title = {Multimodel inference in ecology and evolution: challenges and solutions},
	volume = {24},
	issn = {1420-9101},
	shorttitle = {Multimodel inference in ecology and evolution},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1420-9101.2010.02210.x/abstract},
	doi = {10.1111/j.1420-9101.2010.02210.x},
	abstract = {Information theoretic approaches and model averaging are increasing in popularity, but this approach can be difficult to apply to the realistic, complex models that typify many ecological and evolutionary analyses. This is especially true for those researchers without a formal background in information theory. Here, we highlight a number of practical obstacles to model averaging complex models. Although not meant to be an exhaustive review, we identify several important issues with tentative solutions where they exist (e.g. dealing with collinearity amongst predictors; how to compute model-averaged parameters) and highlight areas for future research where solutions are not clear (e.g. when to use random intercepts or slopes; which information criteria to use when random factors are involved). We also provide a worked example of a mixed model analysis of inbreeding depression in a wild population. By providing an overview of these issues, we hope that this approach will become more accessible to those investigating any process where multiple variables impact an evolutionary or ecological response.},
	language = {en},
	number = {4},
	urldate = {2011-12-15},
	journal = {Journal of Evolutionary Biology},
	author = {Grueber, C. E and Nakagawa, S. and Laws, R. J and Jamieson, I. G},
	year = {2011},
	keywords = {Akaike Information Criterion, generalized linear mixed models, inbreeding, information theory, lethal equivalents, model averaging, random factors, standardized predictors},
	pages = {699--711},
	file = {Wiley Full Text PDF:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/UF4UKU6C/Grueber et al. - 2011 - Multimodel inference in ecology and evolution cha.pdf:application/pdf}
}


@article{brewer_relative_2016,
	title = {The relative performance of {AIC}, {AICC} and {BIC} in the presence of unobserved heterogeneity},
	volume = {7},
	issn = {2041-210X},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12541/abstract},
	doi = {10.1111/2041-210X.12541},
	abstract = {* Model selection is difficult. Even in the apparently straightforward case of choosing between standard linear regression models, there does not yet appear to be consensus in the statistical ecology literature as to the right approach.


* We review recent works on model selection in ecology and subsequently focus on one aspect in particular: the use of the Akaike Information Criterion (AIC) or its small-sample equivalent, AICC. We create a novel framework for simulation studies and use this to study model selection from simulated data sets with a range of properties, which differ in terms of degree of unobserved heterogeneity. We use the results of the simulation study to suggest an approach for model selection based on ideas from information criteria but requiring simulation.


* We find that the relative predictive performance of model selection by different information criteria is heavily dependent on the degree of unobserved heterogeneity between data sets. When heterogeneity is small, AIC or AICC are likely to perform well, but if heterogeneity is large, the Bayesian Information Criterion (BIC) will often perform better, due to the stronger penalty afforded.


* Our conclusion is that the choice of information criterion (or more broadly, the strength of likelihood penalty) should ideally be based upon hypothesized (or estimated from previous data) properties of the population of data sets from which a given data set could have arisen. Relying on a single form of information criterion is unlikely to be universally successful.},
	language = {en},
	number = {6},
	urldate = {2016-06-23},
	journal = {Methods in Ecology and Evolution},
	author = {Brewer, Mark J. and Butler, Adam and Cooksley, Susan L.},
	year = {2016},
	keywords = {Akaike Information Criterion, Bayesian information criterion, generalized linear models, likelihood penalization, linear regression, model selection, statistical controversies},
	pages = {679--692},
	file = {Full Text PDF:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/WFFXG22A/Brewer et al. - 2016 - The relative performance of AIC, AICC and BIC in t.pdf:application/pdf;Snapshot:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/PSTBSECK/abstract.html:text/html}
}


@article{dahlgren_alternative_2010,
	title = {Alternative regression methods are not considered in {Murtaugh} (2009) or by ecologists in general},
	volume = {13},
	issn = {1461-0248},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1461-0248.2010.01460.x/abstract},
	doi = {10.1111/j.1461-0248.2010.01460.x},
	abstract = {Ecology Letters (2010) 13: E7–E9 
Abstract
Murtaugh (2009) recently illustrated that all subsets variable selection is very similar to stepwise regression. This, however, does not necessarily mean both methods are useful. On the contrary, the same problems with overfitting should apply. Ecologists should, if model building is indeed necessary, consider more reliable regression methods now available.},
	language = {en},
	number = {5},
	urldate = {2016-04-14},
	journal = {Ecology Letters},
	author = {Dahlgren, Johan P.},
	year = {2010},
	keywords = {AIC, all subsets, BIC, lasso, ridge regression, Shrinkage, stepwise multiple regression, Variable selection},
	pages = {E7--E9},
	file = {Snapshot:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/ZKQHERDI/abstract.html:text/html}
}


@misc{mcgill_why_2015,
	title = {Why {AIC} appeals to ecologist’s lowest instincts},
	url = {https://dynamicecology.wordpress.com/2015/05/21/why-aic-appeals-to-ecologists-lowest-instincts/},
	urldate = {2015-06-27},
	journal = {Dynamic Ecology},
	author = {McGill, Brian J},
	year = {2015}
}


@article{javanmard_confidence_2014,
	title = {Confidence intervals and hypothesis testing for high-dimensional regression},
	volume = {15},
	url = {http://dl.acm.org/citation.cfm?id=2697057},
	number = {1},
	urldate = {2016-05-24},
	journal = {The Journal of Machine Learning Research},
	author = {Javanmard, Adel and Montanari, Andrea},
	year = {2014},
	pages = {2869--2909},
	file = {javanmard14a.pdf:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/2G8DE2IT/javanmard14a.pdf:application/pdf}
}


@article{lockhart_significance_2014,
	title = {A significance test for the lasso},
	volume = {42},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4285373/},
	number = {2},
	urldate = {2016-05-24},
	journal = {Annals of statistics},
	author = {Lockhart, Richard and Taylor, Jonathan and Tibshirani, Ryan J. and Tibshirani, Robert},
	year = {2014},
	pages = {413},
	file = {covtest.pdf:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/PEXTTUKW/covtest.pdf:application/pdf}
}


@article{lee_exact_2013,
	title = {Exact post-selection inference with the lasso},
	url = {http://xxx.tau.ac.il/abs/1311.6238v4},
	urldate = {2015-07-10},
	author = {Lee, Jason D. and Sun, Dennis L. and Sun, Yuekai and Taylor, Jonathan E.},
	year = {2013}
}


@misc{potscher_confidence_2008,
	type = {{MPRA} {Paper}},
	title = {Confidence sets based on penalized maximum likelihood estimators},
	url = {http://mpra.ub.uni-muenchen.de/16013/},
	abstract = {Confidence intervals based on penalized maximum likelihood estimators such as the LASSO, adaptive LASSO, and hard-thresholding are analyzed. In the known-variance case, the finite-sample coverage properties of such intervals are determined and it is shown that symmetric intervals are the shortest. The length of the shortest intervals based on the hard-thresholding estimator is larger than the length of the shortest interval based on the adaptive LASSO, which is larger than the length of the shortest interval based on the LASSO, which in turn is larger than the standard interval based on the maximum likelihood estimator. In the case where the penalized estimators are tuned to possess the `sparsity property', the intervals based on these estimators are larger than the standard interval by an order of magnitude. Furthermore, a simple asymptotic confidence interval construction in the `sparse' case, that also applies to the smoothly clipped absolute deviation estimator, is discussed.  The results for the known-variance case are shown to carry over to the unknown-variance case in an appropriate asymptotic sense.},
	urldate = {2013-10-31},
	author = {Pötscher, Benedikt M. and Schneider, Ulrike},
	year = {2008},
	keywords = {C01 - Econometrics, C13 - Estimation: General}
}


@article{whittingham_why_2006,
	title = {Why do we still use stepwise modelling in ecology and behaviour?},
	volume = {75},
	number = {5},
	journal = {Journal of Animal Ecology},
	author = {Whittingham, Mark J. and Stephens, Philip A. and Bradbury, Richard B. and Freckleton, Robert P.},
	year = {2006},
	pages = {1182--1189}
}


@book{harrell_regression_2001,
	title = {Regression {Modeling} {Strategies}},
	isbn = {0-387-95232-2},
	publisher = {Springer},
	author = {Harrell, Frank},
	year = {2001}
}


@article{murtaugh_performance_2009,
	title = {Performance of several variable-selection methods applied to real ecological data},
	volume = {12},
	issn = {1461023X, 14610248},
	url = {http://doi.wiley.com/10.1111/j.1461-0248.2009.01361.x},
	doi = {10.1111/j.1461-0248.2009.01361.x},
	language = {en},
	number = {10},
	urldate = {2015-07-11},
	journal = {Ecology Letters},
	author = {Murtaugh, Paul A.},
	year = {2009},
	pages = {1061--1068}
}

@article{brando_fire-induced_2012,
  title={Fire-induced tree mortality in a neotropical forest: the roles of bark traits, tree size, wood density and fire behavior},
  author={Brando, P.M. and Nepstad, D.C. and Balch, J.K. and Bolker, B. and Christman, M.C. and Coe, M. and Putz, F.E.},
  journal={Global Change Biology},
  volume={18},
  number={2},
  pages={630--641},
  year={2012},
  pdf={bbpapers/brando_fire-induced_2012.pdf},
  doi={10.1111/j.1365-2486.2011.02533.x}
}

@article{ghenu_multicopy_2016,
	title = {Multicopy gene family evolution on primate {Y} chromosomes},
	volume = {17},
	issn = {1471-2164},
	url = {http://dx.doi.org/10.1186/s12864-015-2187-8},
	doi = {10.1186/s12864-015-2187-8},
	abstract = {The primate Y chromosome is distinguished by a lack of inter-chromosomal recombination along most of its length, extensive gene loss, and a prevalence of repetitive elements. A group of genes on the male-specific portion of the Y chromosome known as the “ampliconic genes” are present in multiple copies that are sometimes part of palindromes, and that undergo a form of intra-chromosomal recombination called gene conversion, wherein the nucleotides of one copy are homogenized by those of another. With the aim of further understanding gene family evolution of these genes, we collected nucleotide sequence and gene copy number information for several species of papionin monkey. We then tested for evidence of gene conversion, and developed a novel statistical framework to evaluate alternative models of gene family evolution using our data combined with other information from a human, a chimpanzee, and a rhesus macaque.},
	urldate = {2016-08-03},
	journal = {BMC Genomics},
	author = {Ghenu, Ana-Hermina and Bolker, Benjamin M. and Melnick, Don J. and Evans, Ben J.},
	year = {2016},
	keywords = {Ampliconic genes, Gene conversion, Gene duplication, Gene family evolution, Genome structure, Great apes, Old World Monkeys, Y chromosome},
	pages = {157},
	annote = {Pages 1-17 in PDF},
	file = {Full Text PDF:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/S2N7AMKI/Ghenu et al. - 2016 - Multicopy gene family evolution on primate Y chrom.pdf:application/pdf;Snapshot:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/Z4EXFQJE/s12864-015-2187-8.html:text/html}
}

@ARTICLE{Gruner+2008,
  author = {Gruner, D. S. and Smith, J. E. and Seabloom, E. W. and Sandin, S.
	A. and Ngai, J. T. and Hillebrand, H. and Harpole, W. S. and Elser,
	J. J. and Cleland, E. E. and Bracken, M. E. S. and Borer, E. T. and
	Bolker, B. M.},
  title = {A cross-system synthesis of consumer and nutrient resource control
	on producer biomass},
  journal = {Ecology Letters},
  year = {2008},
  volume = {11},
  pages = {740--755},
  number = {7},
  SN = {1461-023X},
  TC = {0},
  UT = {MEDLINE:18445030},
  owner = {ben},
  timestamp = {2008.08.01}
}

@Book{BurnAnde98,
  Author         = {Burnham, Kenneth P. and Anderson, David R.},
  Title          = {Model Selection and Inference: A Practical
                   Information-Theoretic Approach},
  Publisher      = {Springer},
  Address        = {New York},
  year           = 1998
}


@book{burnham_model_2002,
	title = {Model {Selection} and {Multimodel} {Inference}: {A} {Practical} {Information}-theoretic {Approach}},
	isbn = {978-0-387-95364-9},
	shorttitle = {Model {Selection} and {Multimodel} {Inference}},
	abstract = {The second edition of this book is unique in that it focuses on methods for making formal statistical inference from all the models in an a priori set (Multi-Model Inference). A philosophy is presented for model-based data analysis and a general strategy outlined for the analysis of empirical data. The book invites increased attention on a priori science hypotheses and modeling.Kullback-Leibler Information represents a fundamental quantity in science and is Hirotugu Akaike's basis for model selection. The maximized log-likelihood function can be bias-corrected as an estimator of expected, relative Kullback-Leibler information. This leads to Akaike's Information Criterion (AIC) and various extensions. These methods are relatively simple and easy to use in practice, but based on deep statistical theory. The information theoretic approaches provide a unified and rigorous theory, an extension of likelihood theory, an important application of information theory, and are objective and practical to employ across a very wide class of empirical problems.The book presents several new ways to incorporate model selection uncertainty into parameter estimates and estimates of precision. An array of challenging examples is given to illustrate various technical issues.This is an applied book written primarily for biologists and statisticians wanting to make inferences from multiple models and is suitable as a graduate text or as a reference for professional analysts.},
	language = {en},
	publisher = {Springer},
	author = {Burnham, Kenneth P. and Anderson, David R.},
	year = {2002},
	keywords = {biology, Biology/ Mathematical models, Biology - Mathematical models, Mathematical statistics, Mathematics / General, Mathematics / Probability \& Statistics / General, Medical / Biostatistics, Science / General, Science / Life Sciences / Biology}
}

@article{fieberg_mmi_2015,
	title = {{MMI}: {Multimodel} inference or models with management implications?: {Multimodel} {Inference} and {Models} for {Management}},
	volume = {79},
	issn = {0022541X},
	shorttitle = {{MMI}},
	url = {http://doi.wiley.com/10.1002/jwmg.894},
	doi = {10.1002/jwmg.894},
	language = {en},
	number = {5},
	urldate = {2017-04-23},
	journal = {The Journal of Wildlife Management},
	author = {Fieberg, John and Johnson, Douglas H.},
	year = {2015},
	pages = {708--718}
}

@article{galipaud_ecologists_2014,
	title = {Ecologists overestimate the importance of predictor variables in model averaging: a plea for cautious interpretations},
	volume = {5},
	issn = {2041-210X},
	shorttitle = {Ecologists overestimate the importance of predictor variables in model averaging},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12251/abstract},
	doi = {10.1111/2041-210X.12251},
	abstract = {* Information-theory procedures are powerful tools for multimodel inference and are now standard methods in ecology. When performing model averaging on a given set of models, the importance of a predictor variable is commonly estimated by summing the weights of models where the variable appears, the so-called sum of weights (SW). However, SWs have received little methodological attention and are frequently misinterpreted.


* We assessed the reliability of SW by performing model selection and averaging on simulated data sets including variables strongly and weakly correlated to the response variable and a variable unrelated to the response. Our aim was to investigate how useful SWs are to inform about the relative importance of predictor variables.


* SW can take a wide range of possible values, even for predictor variables unrelated to the response. As a consequence, SW with intermediate values cannot be confidently interpreted as denoting importance for the considered predictor variable. Increasing sample size using an alternative information criterion for model selection or using only a subset of candidate models for model averaging did not qualitatively change our results: a variable of a given effect size can take a wide range of SW values.


* Contrary to what is assumed in many ecological studies, it seems hazardous to define a threshold for SW above which a variable is considered as having a statistical effect on the response and SW is not a measure of effect size. Although we did not consider every possible condition of analysis, it is likely that in most situations, SW is a poor estimate of variable's importance.},
	language = {en},
	number = {10},
	urldate = {2016-08-12},
	journal = {Methods in Ecology and Evolution},
	author = {Galipaud, Matthias and Gillingham, Mark A. F. and David, Morgan and Dechaume-Moncharmont, François-Xavier},
	year = {2014},
	keywords = {Akaike Information Criterion, baseline sum of weights, Bayesian information criterion, information theory, model averaging, model selection, multimodel inference, variable importance},
	pages = {983--991}
}


@Article{freckleton_dealing_2011,
  author = 	 {Robert P. Freckleton},
  title = 	 {Dealing with collinearity in behavioural and ecological data: model averaging and the problems of measurement error},
  journal = 	 {Behavioral Ecology and Sociobiology},
  year = 	 {2011},
  volume =	 {65},
  number =	 {1},
  pages =	 {91-101}
}


@article{wenger_assessing_2012,
	Author = {Wenger, Seth J. and Olden, Julian D.},
	Doi = {10.1111/j.2041-210X.2011.00170.x},
	Issn = {2041210X},
	Journal = {Methods in Ecology and Evolution},
	Number = {2},
	Pages = {260--267},
	Shorttitle = {Assessing transferability of ecological models},
	Title = {Assessing transferability of ecological models: an underappreciated aspect of statistical validation},
	Url = {http://doi.wiley.com/10.1111/j.2041-210X.2011.00170.x},
	Urldate = {2013-06-29},
	Volume = {3},
	Year = {2012}}

@Article{obenchain_classical_1977,
  author = 	 {Obenchain, R.},
  title = 	 {Classical $F$-Tests and Confidence Regions for Ridge Regression},
  journal = 	 {Technometrics},
  year = 	 {1977},
  volume =	 {19},
  number =	 {4},
  pages =	 {429-439}
}

@article{turek2012model,
  title={Model-averaged Wald confidence intervals},
  author={Turek, Daniel and Fletcher, David},
  journal={Computational Statistics \& Data Analysis},
  volume={56},
  number={9},
  pages={2809--2815},
  year={2012},
  publisher={Elsevier}
}

@article{turek2015comparison,
  title={Comparison of the Frequentist {MATA} Confidence Interval with {Bayesian} Model-Averaged Confidence Intervals},
  author={Turek, Daniel},
  journal={Journal of Probability and Statistics},
  volume={2015},
  year={2015}
}

@phdthesis{turek2013frequentist,
  title={Frequentist model-averaged confidence intervals},
  author={Turek, Daniel Bernard},
  url={https://www.otago.ourarchive.ac.nz/bitstream/handle/10523/3923/TurekDanielB2013PhD.pdf},
  year={2013},
  school={University of Otago}
}

@article{fletcher2012model,
  title={Model-averaged profile likelihood intervals},
  author={Fletcher, David and Turek, Daniel},
  journal={Journal of agricultural, biological, and environmental statistics},
  volume={17},
  number={1},
  pages={38--51},
  year={2012},
  publisher={Springer}
}

@article{taper_evidential_2015,
	title = {Evidential statistics as a statistical modern synthesis to support 21st century science},
	volume = {58},
	issn = {1438-3896, 1438-390X},
	url = {http://link.springer.com/article/10.1007/s10144-015-0533-y},
	doi = {10.1007/s10144-015-0533-y},
	abstract = {During the 20th century, population ecology and science in general relied on two very different statistical paradigms to solve its inferential problems: error statistics (also referred to as classical statistics and frequentist statistics) and Bayesian statistics. A great deal of good science was done using these tools, but both schools suffer from technical and philosophical difficulties. At the turning of the 21st century (Royall in Statistical evidence: a likelihood paradigm. Chapman \& Hall, London, 1997; Lele in The nature of scientific evidence: statistical, philosophical and empirical considerations. The University of Chicago Press, Chicago, pp 191–216, 2004a), evidential statistics emerged as a seriously contending paradigm. Drawing on and refining elements from error statistics, likelihoodism, Bayesian statistics, information criteria, and robust methods, evidential statistics is a statistical modern synthesis that smoothly incorporates model identification, model uncertainty, model comparison, parameter estimation, parameter uncertainty, pre-data control of error, and post-data strength of evidence into a single coherent framework. We argue that evidential statistics is currently the most effective statistical paradigm to support 21st century science. Despite the power of the evidential paradigm, we think that there is no substitute for learning how to clarify scientific arguments with statistical arguments. In this paper we sketch and relate the conceptual bases of error statistics, Bayesian statistics and evidential statistics. We also discuss a number of misconceptions about the paradigms that have hindered practitioners, as well as some real problems with the error and Bayesian statistical paradigms solved by evidential statistics.},
	language = {en},
	number = {1},
	urldate = {2016-09-07},
	journal = {Population Ecology},
	author = {Taper, Mark L. and Ponciano, José Miguel},
	year = {2015},
	pages = {9--29},
	file = {Snapshot:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/KZXKPZA8/s10144-015-0533-y.html:text/html}
}

@article{walker_defense_2017,
	title = {A Defense Of Model Averaging},
	copyright = {© 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {http://biorxiv.org/content/early/2017/05/03/133785},
	doi = {10.1101/133785},
	abstract = {Model averaging of partial regression coefficients has been criticized for averaging over a set of models with coefficients that are either incommensurable or describe fundamentally different things if there is any correlation (multicollinearity) among the predictors. It is easy to show that partial regression coefficients conditional on different covariates are commensurable. And, partial regression coefficients from different models can have the same meaning if they are used to estimate the effects in a causal model, which derive their meaning from the specified paths and not from the set of covariates. A multiple regression model implicitly specifies a causal model with direct, causal paths from each predictor to the response. Consequently, the partial regression coefficient for a predictor has the same meaning across all sub-models if the goal is estimation of the causal effects that generated the response. In order to clarify the effects of multicollinearity on model-averaged estimates, I compare effect estimates using a small Monte-Carlo simulation. The simulation results show that model-averaged and ridge estimates have increasingly better performance, relative to model selection and full model estimates, as multicollinearity increases.},
	language = {en},
	urldate = {2017-06-02},
	journal = {bioRxiv},
	author = {Walker, Jeffrey A.},
	year = {2017},
	pages = {133785}
}

@techreport{nilsen_confidence_2005,
	type = {Working paper},
	title = {Confidence intervals for the shrinkage estimator},
	url = {https://brage.bibsys.no/xmlui/handle/11250/165518},
	abstract = {Shrinkage estimators have recently become popular in estimation of heterogeneous models on panel data. In this chapter we show that the estimated covariance matrix in the posterior distribution of the shrinkage estimator fails to include the variability of the hyperparameters. Hence, standard confidence intervals for the parameters based on the “estimated posterior” distribution, are too narrow and thus the t-statistic is upward biased. The bootstrap method, which incorporates some of the variability in the hyperparameters, is an alternative method to obtain confidence intervals for the parameters. Our empirical example shows that one has to be aware of the method used, since it can lead to significantly different economic conclusions.},
	language = {eng},
	urldate = {2017-06-02},
	institution = {SNF},
	author = {Nilsen, Odd Bjarte and Asche, Frank and Tveterås, Ragnar},
	year = 2005
}

@article{lukacs_model_2010,
	title = {Model selection bias and {Freedman}’s paradox},
	volume = {62},
	issn = {0020-3157, 1572-9052},
	url = {http://link.springer.com/10.1007/s10463-009-0234-4},
	doi = {10.1007/s10463-009-0234-4},
	language = {en},
	number = {1},
	urldate = {2017-06-02},
	journal = {Annals of the Institute of Statistical Mathematics},
	author = {Lukacs, Paul M. and Burnham, Kenneth P. and Anderson, David R.},
	year = {2010},
	pages = {117--125}
}


@article{zhang_model_2015,
	title = {Model averaging based on {Kullback}-{Leibler} distance},
	volume = {25},
	issn = {1017-0405},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5066877/},
	doi = {10.5705/ss.2013.326},
	abstract = {This paper proposes a model averaging method based on Kullback-Leibler distance under a homoscedastic normal error term. The resulting model average estimator is proved to be asymptotically optimal. When combining least squares estimators, the model average estimator is shown to have the same large sample properties as the Mallows model average (MMA) estimator developed by . We show via simulations that, in terms of mean squared prediction error and mean squared parameter estimation error, the proposed model average estimator is more efficient than the MMA estimator and the estimator based on model selection using the corrected Akaike information criterion in small sample situations. A modified version of the new model average estimator is further suggested for the case of heteroscedastic random errors. The method is applied to a data set from the Hong Kong real estate market.},
	urldate = {2017-06-02},
	journal = {Statistica Sinica},
	author = {Zhang, Xinyu and Zou, Guohua and Carroll, Raymond J.},
	year = {2015},
	pmid = {27761098},
	pmcid = {PMC5066877},
	pages = {1583--1598}
}


@article{kabaila_model-averaged_2016,
	title = {Model-{Averaged} {Confidence} {Intervals}},
	volume = {43},
	issn = {1467-9469},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/sjos.12163/abstract},
	doi = {10.1111/sjos.12163},
	abstract = {We develop an approach to evaluating frequentist model averaging procedures by considering them in a simple situation in which there are two-nested linear regression models over which we average. We introduce a general class of model averaged confidence intervals, obtain exact expressions for the coverage and the scaled expected length of the intervals, and use these to compute these quantities for the model averaged profile likelihood (MPI) and model-averaged tail area confidence intervals proposed by D. Fletcher and D. Turek. We show that the MPI confidence intervals can perform more poorly than the standard confidence interval used after model selection but ignoring the model selection process. The model-averaged tail area confidence intervals perform better than the MPI and postmodel-selection confidence intervals but, for the examples that we consider, offer little over simply using the standard confidence interval for θ under the full model, with the same nominal coverage.},
	language = {en},
	number = {1},
	urldate = {2017-06-02},
	journal = {Scandinavian Journal of Statistics},
	author = {Kabaila, Paul and Welsh, A. H. and Abeysekera, Waruni},
	year = {2016},
	keywords = {Akaike Information Criterion, Confidence Interval, coverage probability, expected length, model selection, nominal coverage, Profile likelihood, regression models, tail area confidence interval},
	pages = {35--48}
}


@book{claeskens_model_2008,
	series = {Cambridge {Series} in {Statistical} and {Probabilistic} {Mathematics}},
	title = {Model {Selection} and {Model} {Averaging}},
	isbn = {978-0-521-85225-8},
	urldate = {2017-06-27},
	publisher = {Cambridge University Press},
	author = {Claeskens, Gerda and Hjort, Nils Lid},
	year = {2008}
}



@article{raup_method_1995,
	title = {The {Method} of {Multiple} {Working} {Hypotheses}},
	volume = {103},
	url = {http://www.jstor.org/stable/30071227},
	number = {3},
	urldate = {2016-08-11},
	journal = {The Journal of Geology},
	author = {Raup, David C. and Chamberlin, T. C.},
	year = {1995},
	pages = {349--354}
}


@book{burnham_model_2002,
	title = {Model {Selection} and {Multimodel} {Inference}: {A} {Practical} {Information}-theoretic {Approach}},
	isbn = {978-0-387-95364-9},
	shorttitle = {Model {Selection} and {Multimodel} {Inference}},
	abstract = {The second edition of this book is unique in that it focuses on methods for making formal statistical inference from all the models in an a priori set (Multi-Model Inference). A philosophy is presented for model-based data analysis and a general strategy outlined for the analysis of empirical data. The book invites increased attention on a priori science hypotheses and modeling.Kullback-Leibler Information represents a fundamental quantity in science and is Hirotugu Akaike's basis for model selection. The maximized log-likelihood function can be bias-corrected as an estimator of expected, relative Kullback-Leibler information. This leads to Akaike's Information Criterion (AIC) and various extensions. These methods are relatively simple and easy to use in practice, but based on deep statistical theory. The information theoretic approaches provide a unified and rigorous theory, an extension of likelihood theory, an important application of information theory, and are objective and practical to employ across a very wide class of empirical problems.The book presents several new ways to incorporate model selection uncertainty into parameter estimates and estimates of precision. An array of challenging examples is given to illustrate various technical issues.This is an applied book written primarily for biologists and statisticians wanting to make inferences from multiple models and is suitable as a graduate text or as a reference for professional analysts.},
	language = {en},
	publisher = {Springer},
	author = {Burnham, Kenneth P. and Anderson, David R.},
	year = {2002},
	keywords = {Biology/ Mathematical models, Biology - Mathematical models, Mathematics / Probability \& Statistics / General, biology, Science / Life Sciences / Biology, Mathematical statistics, Medical / Biostatistics, Mathematics / General, Science / General}
}


@article{hooten_guide_2015,
	title = {A guide to {Bayesian} model selection for ecologists},
	volume = {85},
	issn = {0012-9615},
	url = {http://www.jstor.org/stable/24818229},
	abstract = {The steady upward trend in the use of model selection and Bayesian methods in ecological research has made it clear that both approaches to inference are important for modern analysis of models and data. However, in teaching Bayesian methods and in working with our research colleagues, we have noticed a general dissatisfaction with the available literature on Bayesian model selection and multimodel inference. Students and researchers new to Bayesian methods quickly find that the published advice on model selection is often preferential in its treatment of options for analysis, frequently advocating one particular method above others. The recent appearance of many articles and textbooks on Bayesian modeling has provided welcome background on relevant approaches to model selection in the Bayesian framework, but most of these are either very narrowly focused in scope or inaccessible to ecologists. Moreover, the methodological details of Bayesian model selection approaches are spread thinly throughout the literature, appearing in journals from many different fields. Our aim with this guide is to condense the large body of literature on Bayesian approaches to model selection and multimodel inference and present it specifically for quantitative ecologists as neutrally as possible. We also bring to light a few important and fundamental concepts relating directly to model selection that seem to have gone unnoticed in the ecological literature. Throughout, we provide only a minimal discussion of philosophy, preferring instead to examine the breadth of approaches as well as their practical advantages and disadvantages. This guide serves as a reference for ecologists using Bayesian methods, so that they can better understand their options and can make an informed choice that is best aligned with their goals for inference.},
	number = {1},
	urldate = {2018-01-05},
	journal = {Ecological Monographs},
	author = {Hooten, M. B. and Hobbs, N. T.},
	year = {2015},
	pages = {3--28}
}


@article{van_houwelingen_shrinkage_2001,
	title = {Shrinkage and {Penalized} {Likelihood} as {Methods} to {Improve} {Predictive} {Accuracy}},
	volume = {55},
	issn = {0039-0402},
	url = {http://journals.scholarsportal.info/details/00390402/v55i0001/17_saplamtipa.xml},
	doi = {10.1111/1467-9574.00154},
	abstract = {A review is given of shrinkage and penalization as tools to improve predictive accuracy of regression models. The James-Stein estimator is taken as starting point. Procedures covered are Pre-test Estimation, the Ridge Regression of Hoerl and Kennard, the Shrinkage Estimators of Copas and Van Houwelingen and Le Cessie, the LASSO of Tibshirani and the Garotte of Breiman. An attempt is made to place all these procedures in a unifying framework of semi-Bayesian methodology. Applications are briefly mentioned, but not amply discussed.},
	number = {1},
	urldate = {2018-01-05},
	journal = {Statistica Neerlandica},
	author = {{van Houwelingen}, J. C},
	year = {2001},
	keywords = {Garotte, LASSO, Pre-test Estimation, Ridge Regression},
	pages = {17--34}
}


@article{dormann_model_2018,
	title = {Model averaging in ecology: a review of {Bayesian}, information-theoretic and tactical approaches for predictive inference},
	issn = {0012-9615},
	shorttitle = {Model averaging in ecology},
	url = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecm.1309},
	doi = {10.1002/ecm.1309},
	abstract = {Abstract In ecology, the true causal structure for a given problem is often not known, and several plausible models and thus model predictions exist. It has been claimed that using weighted averages of these models can reduce prediction error, as well as better reflect model selection uncertainty. These claims, however, are often demonstrated by isolated examples. Analysts must better understand under which conditions model averaging can improve predictions and their uncertainty estimates. Moreover, a large range of different model averaging methods exists, raising the question of how they differ regarding in their behaviour and performance. Here, we review the mathematical foundations of model averaging along with the diversity of approaches available. We explain that the error in model?averaged predictions depends on each model's predictive bias and variance, as well as the covariance in predictions between models and uncertainty about model weights. We show that model averaging is particularly useful if the predictive error of contributing model predictions is dominated by variance, and if the covariance between models is low. For noisy data, which predominate in ecology, these conditions will often be met. Many different methods to derive averaging weights exist, from from Bayesian over information?theoretical to cross?validation optimised and resampling approaches. A general recommendation is difficult, because the performance of methods is often context?dependent. Importantly, estimating weights creates some additional uncertainty. As a result, estimated model weights may not always outperform arbitrary fixed weights, such as equal weights for all models. When averaging a set of models with many inadequate models, however, estimating model weights will typically be superior to equal weights. We also investigate the quality of the confidence intervals calculated for model?averaged predictions, showing that they differ greatly in behaviour and seldom manage to achieve nominal coverage. Our overall recommendations stress the importance of non?parametric methods such as cross?validation for a reliable uncertainty quantification of model?averaged predictions. This article is protected by copyright. All rights reserved.},
	urldate = {2018-05-19},
	journal = {Ecological Monographs},
	author = {Dormann, Carsten F. and Calabrese, Justin M. and Guillera-Arroita, Gurutzeta and Matechou, Eleni and Bahn, Volker and Bartoń, Kamil and Beale, Colin M. and Ciuti, Simone and Elith, Jane and Gerstner, Katharina and Guelat, Jérôme and Keil, Petr and Lahoz-Monfort, José J. and Pollock, Laura J. and Reineking, Björn and Roberts, David R. and Schröder, Boris and Thuiller, Wilfried and Warton, David I. and Wintle, Brendan A. and Wood, Simon N. and Wüest, Rafael O. and Hartig, Florian},
	year = {2018},
	keywords = {uncertainty, model averaging, nominal coverage, AIC-weights, ensemble, model combination, prediction averaging}
}


@article{betini_why_2017,
	title = {Why are we not evaluating multiple competing hypotheses in ecology and evolution?},
	volume = {4},
	copyright = {© 2017 The Authors.. Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the original author and source are credited.},
	issn = {2054-5703},
	url = {http://rsos.royalsocietypublishing.org/content/4/1/160756},
	doi = {10.1098/rsos.160756},
	abstract = {The use of multiple working hypotheses to gain strong inference is widely promoted as a means to enhance the effectiveness of scientific investigation. Only 21 of 100 randomly selected studies from the ecological and evolutionary literature tested more than one hypothesis and only eight tested more than two hypotheses. The surprising rarity of application of multiple working hypotheses suggests that this gap between theory and practice might reflect some fundamental issues. Here, we identify several intellectual and practical barriers that discourage us from using multiple hypotheses in our scientific investigation. While scientists have developed a number of ways to avoid biases, such as the use of double-blind controls, we suspect that few scientists are fully aware of the potential influence of cognitive bias on their decisions and they have not yet adopted many techniques available to overcome intellectual and practical barriers in order to improve scientific investigation.},
	language = {en},
	number = {1},
	urldate = {2017-01-11},
	journal = {Royal Society Open Science},
	author = {Betini, Gustavo S. and Avgar, Tal and Fryxell, John M.},
	year = {2017},
	pages = {16056}
}


@article{jones_sensible_2000,
	title = {A {Sensible} {Formulation} of the {Significance} {Test}},
	volume = {5},
	issn = {1082-989x},
	url = {http://journals.scholarsportal.info/details/1082989x/v05i0004/411_asfotst.xml},
	doi = {10.1037//1082-989X.5.4.411},
	abstract = {The conventional procedure for null hypothesis significance testing has long been the target of appropriate criticism. A more reasonable alternative is proposed, one that not only avoids the unrealistic postulation of a null hypothesis but also, for a given parametric difference and a given error probability, is more likely to report the detection of that difference.},
	number = {4},
	urldate = {2018-05-20},
	journal = {Psychological Methods},
	author = {Jones, Lyle V. and Tukey, John W.},
	year = {2000},
	pages = {411--414}
}


@article{elliott_revisiting_2007,
	title = {Revisiting {Chamberlin}: {Multiple} {Working} {Hypotheses} for the 21st {Century}},
	volume = {57},
	issn = {0006-3568},
	shorttitle = {Revisiting {Chamberlin}},
	url = {https://academic.oup.com/bioscience/article/57/7/608/238555},
	doi = {10.1641/B570708},
	abstract = {Abstract.  The method of multiple working hypotheses, developed by the 19th-century geologist T. C. Chamberlin, is an important philosophical contribution to th},
	language = {en},
	number = {7},
	urldate = {2018-06-21},
	journal = {BioScience},
	author = {Elliott, Louis P. and Brook, Barry W.},
	year = {2007},
	pages = {608--614}
}


@misc{hardy_machine_2017,
	title = {machine learning - {Speed}, computational expenses of {PCA}, {LASSO}, elastic net},
	url = {https://stats.stackexchange.com/questions/177665/speed-computational-expenses-of-pca-lasso-elastic-net},
	urldate = {2018-06-23},
	journal = {Cross Validated},
	author = {Hardy, Richard},
	year = {2017}
}


@phdthesis{louppe_understanding_2014,
	address = {Faculty of Applied Sciences, Department of Electrical Engineering \& Computer Science},
	type = {{PhD} {Thesis}},
	title = {Understanding random forests: {From} theory to practice},
	shorttitle = {Understanding random forests},
	url = {https://arxiv.org/pdf/1407.7502},
	school = {University of Liège},
	author = {Louppe, Gilles},
	year = {2014}
}


@article{crome_novel_1996,
	title = {A {Novel} {Bayesian} {Approach} to {Assessing} {Impacts} of {Rain} {Forest} {Logging}},
	volume = {6},
	journal = {Ecological Applications},
	author = {Crome, F. H. J. and Thomas, M. R. and Moore, L. A.},
	year = {1996},
	pages = {1104--1123}
}


@article{schomaker_when_2018,
	title = {When and when not to use optimal model averaging},
	issn = {1613-9798},
	url = {https://doi.org/10.1007/s00362-018-1048-3},
	doi = {10.1007/s00362-018-1048-3},
	abstract = {Traditionally model averaging has been viewed as an alternative to model selection with the ultimate goal to incorporate the uncertainty associated with the model selection process in standard errors and confidence intervals by using a weighted combination of candidate models. In recent years, a new class of model averaging estimators has emerged in the literature, suggesting to combine models such that the squared risk, or other risk functions, are minimized. We argue that, contrary to popular belief, these estimators do not necessarily address the challenges induced by model selection uncertainty, but should be regarded as attractive complements for the machine learning and forecasting literature, as well as tools to identify causal parameters. We illustrate our point by means of several targeted simulation studies.},
	language = {en},
	urldate = {2018-11-25},
	journal = {Statistical Papers},
	author = {Schomaker, Michael and Heumann, Christian},
	month = sep,
	year = {2018},
	keywords = {Causal inference, Machine learning, Model averaging, Model selection, Prediction}
}


@book{fletcher_model_2018,
	address = {Berlin Heidelberg},
	series = {{SpringerBriefs} in {Statistics}},
	title = {Model {Averaging}},
	isbn = {978-3-662-58540-5},
	url = {//www.springer.com/us/book/9783662585405},
	abstract = {This book provides a concise and accessible overview of model averaging, with a focus on applications. Model averaging is a common means of allowing for model uncertainty when analysing data, and has been used in a wide range of application areas, such as ecology, econometrics, meteorology and pharmacology. The book presents an overview of the methods developed in this area, illustrating many of them with examples from the life sciences involving real-world data. It also includes an extensive list of references and suggestions for further research. Further, it clearly demonstrates the links between the methods developed in statistics, econometrics and machine learning, as well as the connection between the Bayesian and frequentist approaches to model averaging. The book appeals to statisticians and scientists interested in what methods are available, how they differ and what is known about their properties. It is assumed that readers are familiar with the basic concepts of statistical theory and modelling, including probability, likelihood and generalized linear models.},
	language = {en},
	urldate = {2018-11-25},
	publisher = {Springer-Verlag},
	author = {Fletcher, David},
	year = {2018}
}


@article{fletcher_model-averaged_2011,
	title = {Model-averaged confidence intervals for factorial experiments},
	volume = {55},
	issn = {01679473},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167947311001800},
	doi = {10.1016/j.csda.2011.05.014},
	language = {en},
	number = {11},
	urldate = {2015-07-06},
	journal = {Computational Statistics \& Data Analysis},
	author = {Fletcher, David and Dillingham, Peter W.},
	month = nov,
	year = {2011},
	pages = {3041--3048}
}